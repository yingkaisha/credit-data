{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8529b16-91d6-415c-b75a-ff9c2668c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "from distributed import Client\n",
    "from dask_jobqueue import PBSCluster\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import delayed\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce8c40-dff2-40a8-b3b6-1249e44aafa7",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6eddbc-7e02-4c35-b93f-49878e2de056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get dates 15 days before and after a given day of the year\n",
    "def get_dates_15_days_around(day_of_year, dminus, dplus, string_format_forecast_File='%Y-%m-%dT%H:%M:%S.%fZ', file_interval=0.5):\n",
    "    current_year = datetime.now().year\n",
    "    date_obj = datetime.strptime(f\"{current_year} {day_of_year:03d}\", \"%Y %j\")\n",
    "    dates_list = []\n",
    "    for delta in np.arange(dminus, dplus + 1, file_interval):\n",
    "        date = date_obj + timedelta(days=delta)\n",
    "        date_str = date.strftime(string_format_forecast_File).replace('Z', '.000000000')\n",
    "        dates_list.append(date_str)\n",
    "    return dates_list\n",
    "\n",
    "def find_intersections(dates_get, DS1_time):\n",
    "    # Convert DS1_time to list of strings if they are datetime64\n",
    "    DS1_time_str = [str(date) for date in DS1_time]\n",
    "    \n",
    "    # Process dates_get to match format of DS1_time entries\n",
    "    dates_get_processed = [date.replace('.000000.000000000', '.000000000') for date in dates_get]\n",
    "    \n",
    "    # Strip the year from DS1_time entries\n",
    "    DS1_time_no_year = [date[4:] for date in DS1_time_str]\n",
    "    \n",
    "    # Find intersections without the year\n",
    "    intersection = [date for date in DS1_time_str if date[4:] in dates_get_processed]\n",
    "    \n",
    "    return intersection\n",
    "\n",
    "\n",
    "def gaussian_weights(dates, target_date, sigma):\n",
    "    # Convert target date to datetime object\n",
    "    target_date = datetime.strptime(target_date, \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    weights = []\n",
    "    for date in dates:\n",
    "        # Convert date to datetime object\n",
    "        date = datetime.strptime(date, \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "        # Calculate the difference in days\n",
    "        delta_days = (date - target_date).days\n",
    "        # Calculate the Gaussian weight\n",
    "        weight = np.exp(-0.5 * (delta_days / sigma) ** 2)\n",
    "        weights.append(weight)\n",
    "    return np.array(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3d7ab-62b3-4b65-a28f-af23650a14fb",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c068aea-3dc2-4fcd-99f6-16cf289ee539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask cluster setup\n",
    "project_num = 'NAML0001'\n",
    "cluster = PBSCluster(account=project_num,\n",
    "                         walltime='04:00:00',\n",
    "                         cores=1,\n",
    "                         memory='25GB',\n",
    "                         shared_temp_directory='/glade/derecho/scratch/wchapman/tmp',\n",
    "                         queue='casper')\n",
    "\n",
    "cluster.scale(jobs=22)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca9409-5957-4618-8e4e-8405bbbbf7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirin = '/glade/campaign/cisl/aiml/ERA5_Forecasts/'\n",
    "FNS = sorted(glob.glob(dirin+\"*.zarr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f28e5b-1234-48e5-98c7-3906bead5c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS2 = xr.open_zarr(FNS[0])\n",
    "DS1 = xr.open_zarr(FNS[1])\n",
    "DS1_time = np.array(DS1['time'])\n",
    "DS2_time = np.array(DS2['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4db076-ccb0-426a-bd32-8e5d5903d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddo = pd.date_range(start='2020-01-01',end='2021-01-01',freq='12h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5479c300-91b4-49de-a207-20a03c5d9d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask.array as da\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Function to get dates 15 days before and after a given day of the year\n",
    "def get_dates_15_days_around(day_of_year, dminus, dplus, string_format_forecast_File, file_interval=0.5):\n",
    "    current_year = datetime.now().year\n",
    "    date_obj = datetime.strptime(f\"{current_year} {day_of_year:03d}\", \"%Y %j\")\n",
    "    dates_list = []\n",
    "    for delta in np.arange(dminus, dplus + 1, file_interval):\n",
    "        date = date_obj + timedelta(days=delta)\n",
    "        date_str = date.strftime(string_format_forecast_File).replace('Z', '.000000000')\n",
    "        dates_list.append(date_str)\n",
    "    return dates_list\n",
    "\n",
    "# Function to find intersections without the year\n",
    "def find_intersections(dates_get, DS1_time):\n",
    "    DS1_time_str = [str(date) for date in DS1_time]\n",
    "    dates_get_processed = [date.replace('.000000.000000000', '.000000000') for date in dates_get]\n",
    "    DS1_time_no_year = [date[4:] for date in DS1_time_str]\n",
    "    intersection = [date for date in DS1_time_str if date[4:] in dates_get_processed]\n",
    "    return intersection\n",
    "\n",
    "# Function to calculate Gaussian weights with wrapping around the year\n",
    "def gaussian_weights(dates, target_doy, sigma):\n",
    "    weights = []\n",
    "    for date in dates:\n",
    "        date_doy = datetime.strptime(date[:10], \"%Y-%m-%d\").timetuple().tm_yday\n",
    "        delta_days = min(abs(date_doy - target_doy), 365 - abs(date_doy - target_doy))\n",
    "        weight = np.exp(-0.5 * (delta_days / sigma) ** 2)\n",
    "        weights.append(weight)\n",
    "    return np.array(weights)\n",
    "\n",
    "# Example usage\n",
    "sigma = 10  # Standard deviation for Gaussian decay\n",
    "ddo = pd.date_range(start='2020-01-01',end='2021-01-01',freq='12h')\n",
    "# Assuming DS1, DS2, DS1_time, DS2_time, and ddo are already defined\n",
    "for tt in ddo:\n",
    "    target_doy = tt.dayofyear\n",
    "    output_file = f'/glade/derecho/scratch/wchapman/IFS_forecast_climo/IFS_forecast_climo_{target_doy:03}.nc'\n",
    "    print(f'attempting: {output_file}')\n",
    "    # Check if the output file already exists\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"File {output_file} already exists. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    dates_get = get_dates_15_days_around(target_doy, -15, 15, string_format_forecast_File='-%m-%dT%H:%M:%S.%fZ', file_interval=0.5)\n",
    "    \n",
    "    intersections1 = find_intersections(dates_get, DS1_time)\n",
    "    DD1 = DS1.sel(time=intersections1)\n",
    "    \n",
    "    intersections2 = find_intersections(dates_get, DS2_time)\n",
    "    DD2 = DS2.sel(time=intersections2)\n",
    "    \n",
    "    DS1_subset_time = DD1['time']\n",
    "    DS2_subset_time = DD2['time']\n",
    "    \n",
    "    weights1 = gaussian_weights([str(date) for date in DS1_subset_time.values], target_doy, sigma)\n",
    "    weights2 = gaussian_weights([str(date) for date in DS2_subset_time.values], target_doy, sigma)\n",
    "\n",
    "    weights3 = weights1 / (np.sum(weights1) + np.sum(weights2))\n",
    "    weights4 = weights2 / (np.sum(weights1) + np.sum(weights2))\n",
    "\n",
    "    weights3_da = da.from_array(weights3, chunks=(len(weights3),))\n",
    "    weights4_da = da.from_array(weights4, chunks=(len(weights4),))\n",
    "\n",
    "    DD1_weighted = DD1 * weights3_da[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "    DD2_weighted = DD2 * weights4_da[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "\n",
    "    combined = xr.combine_by_coords([DD1_weighted, DD2_weighted]).sum('time')\n",
    "    combined = combined.persist()  # Persist the combined result to optimize memory usage\n",
    "    combined.to_netcdf(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a9b49-3a49-4e1c-950b-6f4d7094c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'/glade/derecho/scratch/wchapman/IFS_forecast_climo/Forecast_climo_{target_doy:03}.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b3383-ffa3-49d0-9765-df097b0c6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b5c0b-ddab-4f2a-9824-23a2d15fa5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm dask-worker*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609fd88b-d40b-4838-8d28-beb1ee1811c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

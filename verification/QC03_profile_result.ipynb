{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926e728c-5a86-4ebe-84b2-6566c29b2047",
   "metadata": {},
   "source": [
    "# Profiling `train_multistep.py` and `trainerERA5_multistep_grad_accum.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c9fbc-43ae-47e6-a01c-501b755bbf35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e188b77-0b97-4eb1-8992-a5d08611a69e",
   "metadata": {},
   "source": [
    "## `train_multistep.py`\n",
    "\n",
    "```python\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "   241                                           def main(rank, world_size, conf, backend, trial=False):\n",
    "   242                                               \"\"\"\n",
    "   243                                               Main function to set up training and validation processes.\n",
    "   244\n",
    "   245                                               Args:\n",
    "   246                                                   rank (int): Rank of the current process.\n",
    "   247                                                   world_size (int): Number of processes participating in the job.\n",
    "   248                                                   conf (dict): Configuration dictionary containing model, data, and training parameters.\n",
    "   249                                                   backend (str): Backend to be used for distributed training.\n",
    "   250                                                   trial (bool, optional): Flag for whether this is an Optuna trial. Defaults to False.\n",
    "   251\n",
    "   252                                               Returns:\n",
    "   253                                                   Any: The result of the training process.\n",
    "   254                                               \"\"\"\n",
    "   255\n",
    "   256                                               # convert $USER to the actual user name\n",
    "   257         1      16301.0  16301.0      0.0      conf['save_loc'] = os.path.expandvars(conf['save_loc'])\n",
    "   258\n",
    "   259         1       1322.0   1322.0      0.0      if conf[\"trainer\"][\"mode\"] in [\"fsdp\", \"ddp\"]:\n",
    "   260         1  313010857.0    3e+08      0.0          setup(rank, world_size, conf[\"trainer\"][\"mode\"], backend)\n",
    "   261\n",
    "   262                                               # infer device id from rank\n",
    "   263\n",
    "   264         1      26461.0  26461.0      0.0      device = torch.device(f\"cuda:{rank % torch.cuda.device_count()}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "   265         1 1184547466.0    1e+09      0.0      torch.cuda.set_device(rank % torch.cuda.device_count())\n",
    "   266\n",
    "   267                                               # Config settings\n",
    "   268         1       3076.0   3076.0      0.0      seed = 1000 if \"seed\" not in conf else conf[\"seed\"]\n",
    "   269         1   32462283.0    3e+07      0.0      seed_everything(seed)\n",
    "   270\n",
    "   271         1       1232.0   1232.0      0.0      train_batch_size = conf['trainer']['train_batch_size']\n",
    "   272         1        501.0    501.0      0.0      valid_batch_size = conf['trainer']['valid_batch_size']\n",
    "   273\n",
    "   274                                               # get file names\n",
    "   275         1   45995972.0    5e+07      0.0      all_ERA_files = sorted(glob(conf[\"data\"][\"save_loc\"]))\n",
    "   276\n",
    "   277                                               # <------------------------------------------ std_new or 'std_cached'\n",
    "   278         1       1844.0   1844.0      0.0      if conf['data']['scaler_type'] == 'std_new' or 'std_cached':\n",
    "   279\n",
    "   280                                                   # check and glob surface files\n",
    "   281         1       2815.0   2815.0      0.0          if ('surface_variables' in conf['data']) and (len(conf['data']['surface_variables']) > 0):\n",
    "   282         1     857703.0 857703.0      0.0              surface_files = sorted(glob(conf[\"data\"][\"save_loc_surface\"]))\n",
    "   283\n",
    "   284                                                   else:\n",
    "   285                                                       surface_files = None\n",
    "   286\n",
    "   287                                                   # check and glob dyn forcing files\n",
    "   288         1       1773.0   1773.0      0.0          if ('dynamic_forcing_variables' in conf['data']) and (len(conf['data']['dynamic_forcing_variables']) > 0):\n",
    "   289         1     434206.0 434206.0      0.0              dyn_forcing_files = sorted(glob(conf[\"data\"][\"save_loc_dynamic_forcing\"]))\n",
    "   290\n",
    "   291                                                   else:\n",
    "   292                                                       dyn_forcing_files = None\n",
    "   293\n",
    "   294                                                   # check and glob diagnostic files\n",
    "   295         1       1563.0   1563.0      0.0          if ('diagnostic_variables' in conf['data']) and (len(conf['data']['diagnostic_variables']) > 0):\n",
    "   296                                                       diagnostic_files = sorted(glob(conf[\"data\"][\"save_loc_diagnostic\"]))\n",
    "   297\n",
    "   298                                                   else:\n",
    "   299         1        221.0    221.0      0.0              diagnostic_files = None\n",
    "   300\n",
    "   301                                               # -------------------------------------------------- #\n",
    "   302                                               # import training / validation years from conf\n",
    "   303\n",
    "   304         1        672.0    672.0      0.0      if 'train_years' in conf['data']:\n",
    "   305         1        511.0    511.0      0.0          train_years_range = conf['data']['train_years']\n",
    "   306                                               else:\n",
    "   307                                                   train_years_range = [1979, 2014]\n",
    "   308\n",
    "   309         1        521.0    521.0      0.0      if 'valid_years' in conf['data']:\n",
    "   310         1        250.0    250.0      0.0          valid_years_range = conf['data']['valid_years']\n",
    "   311                                               else:\n",
    "   312                                                   valid_years_range = [2014, 2018]\n",
    "   313\n",
    "   314                                               # convert year info to str for file name search\n",
    "   315         1      13856.0  13856.0      0.0      train_years = [str(year) for year in range(train_years_range[0], train_years_range[1])]\n",
    "   316         1       2545.0   2545.0      0.0      valid_years = [str(year) for year in range(valid_years_range[0], valid_years_range[1])]\n",
    "   317\n",
    "   318                                               # Filter the files for training / validation\n",
    "   319         1     218851.0 218851.0      0.0      train_files = [file for file in all_ERA_files if any(year in file for year in train_years)]\n",
    "   320         1      33184.0  33184.0      0.0      valid_files = [file for file in all_ERA_files if any(year in file for year in valid_years)]\n",
    "   321\n",
    "   322                                               # <----------------------------------- std_new or 'std_cached'\n",
    "   323         1        561.0    561.0      0.0      if conf['data']['scaler_type'] == 'std_new' or 'std_cached':\n",
    "   324\n",
    "   325         1        161.0    161.0      0.0          if surface_files is not None:\n",
    "   326\n",
    "   327         1     214624.0 214624.0      0.0              train_surface_files = [file for file in surface_files if any(year in file for year in train_years)]\n",
    "   328         1      32082.0  32082.0      0.0              valid_surface_files = [file for file in surface_files if any(year in file for year in valid_years)]\n",
    "   329\n",
    "   330                                                   else:\n",
    "   331                                                       train_surface_files = None\n",
    "   332                                                       valid_surface_files = None\n",
    "   333\n",
    "   334         1        391.0    391.0      0.0          if dyn_forcing_files is not None:\n",
    "   335\n",
    "   336         1     239712.0 239712.0      0.0              train_dyn_forcing_files = [file for file in dyn_forcing_files if any(year in file for year in train_years)]\n",
    "   337         1      33745.0  33745.0      0.0              valid_dyn_forcing_files = [file for file in dyn_forcing_files if any(year in file for year in valid_years)]\n",
    "   338\n",
    "   339                                                   else:\n",
    "   340                                                       train_dyn_forcing_files = None\n",
    "   341                                                       valid_dyn_forcing_files = None\n",
    "   342\n",
    "   343         1        241.0    241.0      0.0          if diagnostic_files is not None:\n",
    "   344\n",
    "   345                                                       train_diagnostic_files = [file for file in diagnostic_files if any(year in file for year in train_years)]\n",
    "   346                                                       valid_diagnostic_files = [file for file in diagnostic_files if any(year in file for year in valid_years)]\n",
    "   347\n",
    "   348                                                   else:\n",
    "   349         1        161.0    161.0      0.0              train_diagnostic_files = None\n",
    "   350         1        131.0    131.0      0.0              valid_diagnostic_files = None\n",
    "   351\n",
    "   352                                               # load Timer unit: 1e-09 s\n",
    "   353         2        3e+10    1e+10      0.8      train_dataset, train_sampler = load_dataset_and_sampler(conf,\n",
    "   354         1        131.0    131.0      0.0                                                              train_files,\n",
    "   355         1        100.0    100.0      0.0                                                              train_surface_files,\n",
    "   356         1        100.0    100.0      0.0                                                              train_dyn_forcing_files,\n",
    "   357         1        100.0    100.0      0.0                                                              train_diagnostic_files,\n",
    "   358         1        231.0    231.0      0.0                                                              world_size, rank, is_train=True)\n",
    "   359                                               # validation set and sampler\n",
    "   360         2  223009470.0    1e+08      0.0      valid_dataset, valid_sampler = load_dataset_and_sampler(conf,\n",
    "   361         1        180.0    180.0      0.0                                                              valid_files,\n",
    "   362         1        241.0    241.0      0.0                                                              valid_surface_files,\n",
    "   363         1        251.0    251.0      0.0                                                              valid_dyn_forcing_files,\n",
    "   364         1        120.0    120.0      0.0                                                              valid_diagnostic_files,\n",
    "   365         1        381.0    381.0      0.0                                                              world_size, rank, is_train=False)\n",
    "   366\n",
    "   367                                               # setup the dataloder for this process\n",
    "   368\n",
    "   369         2     587722.0 293861.0      0.0      train_loader = torch.utils.data.DataLoader(\n",
    "   370         1        401.0    401.0      0.0          train_dataset,\n",
    "   371         1        171.0  \"mode\"], backend)\n",
    "   372         1        391.0    391.0      0.0          shuffle=False,\n",
    "   373         1        250.0    250.0      0.0          sampler=train_sampler,\n",
    "   374         1        151.0    151.0      0.0          pin_memory=True,\n",
    "   375         1        151.0    151.0      0.0          persistent_workers=False,\n",
    "   376         1        221.0    221.0      0.0          num_workers=1,  # multiprocessing is handled in the dataset\n",
    "   377         1        160.0    160.0      0.0          drop_last=True,\n",
    "   378         1        140.0    140.0      0.0          prefetch_factor=4\n",
    "   379                                               )\n",
    "   380\n",
    "   381         2      33534.0  16767.0      0.0      valid_loader = torch.utils.data.DataLoader(\n",
    "   382         1        130.0    130.0      0.0          valid_dataset,\n",
    "   383         1        180.0    180.0      0.0          batch_size=valid_batch_size,\n",
    "   384         1        230.0    230.0      0.0          shuffle=False,\n",
    "   385         1        140.0    140.0      0.0          sampler=valid_sampler,\n",
    "   386         1        140.0    140.0      0.0          pin_memory=False,\n",
    "   387         1        140.0    140.0      0.0          num_workers=1,  # multiprocessing is handled in the dataset\n",
    "   388         1         90.0     90.0      0.0          drop_last=True,\n",
    "   389         1         90.0     90.0      0.0          prefetch_factor=4\n",
    "   390                                               )\n",
    "   391\n",
    "   392                                               # model\n",
    "   393\n",
    "   394         1 2828381656.0    3e+09      0.1      m = load_model(conf)\n",
    "   395\n",
    "   396                                               # have to send the module to the correct device first\n",
    "   397\n",
    "   398         1  496232366.0    5e+08      0.0      m.to(device)\n",
    "399\n",
    "   400                                               # move out of eager-mode\n",
    "   401         1       3106.0   3106.0      0.0      if conf[\"trainer\"].get(\"compile\", False):\n",
    "   402                                                   m = torch.compile(m)\n",
    "   403\n",
    "   404                                               # Wrap in DDP or FSDP module, or none\n",
    "   405\n",
    "   406         1 7956198312.0    8e+09      0.2      model = distributed_model_wrapper(conf, m, device)\n",
    "   407\n",
    "   408                                               # Load model weights (if any), an optimizer, scheduler, and gradient scaler\n",
    "   409\n",
    "   410         1        1e+10    1e+10      0.4      conf, model, optimizer, scheduler, scaler = load_model_states_and_optimizer(conf, model, device)\n",
    "   411\n",
    "   412                                               # Train and validation losses\n",
    "   413\n",
    "   414         1  831897166.0    8e+08      0.0      train_criterion = VariableTotalLoss2D(conf)\n",
    "   415         1   12467354.0    1e+07      0.0      valid_criterion = VariableTotalLoss2D(conf, validation=True)\n",
    "   416\n",
    "   417                                               # Optional load stopping probability annealer\n",
    "   418\n",
    "   419                                               # Set up some metrics\n",
    "   420\n",
    "   421         1   11567129.0    1e+07      0.0      metrics = LatWeightedMetrics(conf)\n",
    "   422\n",
    "   423                                               # Initialize a trainer object\n",
    "   424         1     655323.0 655323.0      0.0      trainer_cls = load_trainer(conf)\n",
    "   425         1      93931.0  93931.0      0.0      trainer = trainer_cls(model, rank, module=(conf[\"trainer\"][\"mode\"] == \"ddp\"))\n",
    "   426\n",
    "   427                                               # Fit the model\n",
    "   428\n",
    "   429         2        4e+12    2e+12     98.4      result = trainer.fit(\n",
    "   430         1        121.0    121.0      0.0          conf,\n",
    "   431         1        341.0    341.0      0.0          train_loader=train_loader,\n",
    "   432         1        251.0    251.0      0.0          valid_loader=valid_loader,\n",
    "   433         1        220.0    220.0      0.0          optimizer=optimizer,\n",
    "   434         1        250.0    250.0      0.0          train_criterion=train_criterion,\n",
    "   435         1        140.0    140.0      0.0          valid_criterion=valid_criterion,\n",
    "   436         1        141.0    141.0      0.0          scaler=scaler,\n",
    "   437         1        100.0    100.0      0.0          scheduler=scheduler,\n",
    "   438         1        141.0    141.0      0.0          metrics=metrics,\n",
    "   439         1        120.0    120.0      0.0          trial=trial  # Optional\n",
    "   440                                               )\n",
    "   441\n",
    "   442         1       1563.0   1563.0      0.0      return result\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb6287f9-dd6e-4b62-83f9-d6c8079a670f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "356aad9f-cc73-4c11-997a-19c34b02989c",
   "metadata": {},
   "source": [
    "## `trainer.fit`\n",
    "\n",
    "```python\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "   169                                               def fit(\n",
    "   170                                                   self,\n",
    "   171                                                   conf: Dict[str, Any],\n",
    "   172                                                   train_loader: DataLoader,\n",
    "   173                                                   valid_loader: DataLoader,\n",
    "   174                                                   optimizer: Optimizer,\n",
    "   175                                                   train_criterion: torch.nn.Module,\n",
    "   176                                                   valid_criterion: torch.nn.Module,\n",
    "   177                                                   scaler: GradScaler,\n",
    "   178                                                   scheduler: _LRScheduler,\n",
    "   179                                                   metrics: Dict[str, Any],\n",
    "   180                                                   rollout_scheduler: Optional[callable] = None,\n",
    "   181                                                   trial: bool = False\n",
    "   182                                               ) -> Dict[str, Any]:\n",
    "   183\n",
    "   184                                                   \"\"\"\n",
    "   185                                                   Fit the model to the data.\n",
    "   186\n",
    "   187                                                   Args:\n",
    "   188                                                       conf (Dict[str, Any]): Configuration dictionary.\n",
    "   189                                                       train_loader (DataLoader): DataLoader for training data.\n",
    "   190                                                       valid_loader (DataLoader): DataLoader for validation data.\n",
    "   191                                                       optimizer (Optimizer): The optimizer to use for training.\n",
    "   192                                                       train_criterion (torch.nn.Module): Loss function for training.\n",
    "   193                                                       valid_criterion (torch.nn.Module): Loss function for validation.\n",
    "   194                                                       scaler (GradScaler): Gradient scaler for mixed precision training.\n",
    "   195                                                       scheduler (_LRScheduler): Learning rate scheduler.\n",
    "   196                                                       metrics (Dict[str, Any]): Dictionary of metrics to track during training.\n",
    "   197                                                       rollout_scheduler (Optional[callable]): Function to schedule rollout probability, if applicable.\n",
    "   198                                                       trial (bool): Whether this is a trial run (e.g., for hyperparameter tuning).\n",
    "   199\n",
    "   200                                                   Returns:\n",
    "   201                                                       Dict[str, Any]: Dictionary containing the best results from training.\n",
    "   202                                                   \"\"\"\n",
    "   203\n",
    "   204                                                   # convert $USER to the actual user name\n",
    "   205         1       3607.0   3607.0      0.0          conf['save_loc'] = save_loc = os.path.expandvars(conf['save_loc'])\n",
    "   206\n",
    "   207                                                   # training hyperparameters\n",
    "   208         1        451.0    451.0      0.0          start_epoch = conf['trainer']['start_epoch']\n",
    "   209         1        311.0    311.0      0.0          epochs = conf['trainer']['epochs']\n",
    "   210         1        592.0    592.0      0.0          skip_validation = conf['trainer']['skip_validation'] if 'skip_validation' in conf['trainer'] else False\n",
    "   211         1        371.0    371.0      0.0          flag_load_weights = conf['trainer']['load_weights']\n",
    "   212\n",
    "   213                                                   # Check if 'training_metric' and 'training_metric_direction' exist in the config\n",
    "   214         1        621.0    621.0      0.0          training_metric = conf['trainer'].get('training_metric', \"train_loss\" if skip_validation else \"valid_loss\")\n",
    "   215         1        531.0    531.0      0.0          direction = conf['trainer'].get('training_metric_direction', \"min\")\n",
    "   216         1      58523.0  58523.0      0.0          logger.info(f\"The training metric being used is {training_metric} which has direction {direction}\")\n",
    "   217         1        611.0    611.0      0.0          direction = min if direction == \"min\" else max\n",
    "   218\n",
    "   219                                                   # Check if we are saving user-defined variable metrics\n",
    "   220         1        701.0    701.0      0.0          save_metric_vars = conf['trainer'].get('save_metric_vars', [])\n",
    "   221\n",
    "   222                                                   # =========================================== #\n",
    "   223                                                   # user can specify to run a fixed number of epochs\n",
    "   224         1        421.0    421.0      0.0          if 'num_epoch' in conf['trainer']:\n",
    "   225         1      40538.0  40538.0      0.0              logger.info('The current job will run {} epochs max'.format(conf['trainer']['num_epoch']))\n",
    "   226                                                   else:\n",
    "   227                                                       conf['trainer']['num_epoch'] = 1e8\n",
    "   228                                                   # =========================================== #\n",
    "   229\n",
    "   230                                                   # Reload the results saved in the training csv if continuing to train\n",
    "   231         1        340.0    340.0      0.0          if (start_epoch == 0) or (flag_load_weights is False):\n",
    "   232                                                       results_dict = defaultdict(list)\n",
    "   233                                                       # Set start_epoch to the length of the training log and train for one epoch\n",
    "   234                                                       # This is a manual override, you must use train_one_epoch = True\n",
    "   235                                                       if \"train_one_epoch\" in conf[\"trainer\"] and conf[\"trainer\"][\"train_one_epoch\"]:\n",
    "   236                                                           epochs = 1\n",
    "   237                                                   else:\n",
    "   238         1        901.0    901.0      0.0              results_dict = defaultdict(list)\n",
    "   239         1  116185865.0    1e+08      0.0              saved_results = pd.read_csv(os.path.join(save_loc, \"training_log.csv\"))\n",
    "   240\n",
    "   241                                                       # Set start_epoch to the length of the training log and train for one epoch\n",
    "   242                                                       # This is a manual override, you must use train_one_epoch = True\n",
    "   243         1       1603.0   1603.0      0.0              if \"train_one_epoch\" in conf[\"trainer\"] and conf[\"trainer\"][\"train_one_epoch\"]:\n",
    "   244                                                           start_epoch = len(saved_results)\n",
    "   245                                                           epochs = start_epoch + 1\n",
    "   246\n",
    "   247        12      16802.0   1400.2      0.0              for key in saved_results.columns:\n",
    "   248        11       4580.0    416.4      0.0                  if key == \"index\":\n",
    "   249         1        191.0    191.0      0.0                      continue\n",
    "   250        10  141702870.0    1e+07      0.0                  results_dict[key] = list(saved_results[key])\n",
    "   251\n",
    "   252         1        340.0    340.0      0.0          count = 0\n",
    "   253         2       2054.0   1027.0      0.0          for epoch in range(start_epoch, epochs):\n",
    "   254\n",
    "   255         2       2173.0   1086.5      0.0              if count >= conf['trainer']['num_epoch']:\n",
    "   256         1     159267.0 159267.0      0.0                  logger.info('Completed {} epochs, exiting'.format(conf['trainer']['num_epoch']))\n",
    "   257         1       1122.0   1122.0      0.0                  break\n",
    "   258\n",
    "   259                                                       # ========================= #\n",
    "   260                                                       # backup the previous epoch\n",
    "   261                                                       # ========================= #\n",
    "   262         1        631.0    631.0      0.0              if count > 0 and conf['trainer']['save_backup_weights']:\n",
    "   263                                                           if self.rank == 0:\n",
    "   264                                                               # checkpoint.pt\n",
    "   265                                                               shutil.copyfile(os.path.join(save_loc, \"checkpoint.pt\"),\n",
    "   266                                                                               os.path.join(save_loc, \"backup_checkpoint.pt\"))\n",
    "   267\n",
    "   268                                                               # model_checkpoint.pt and optimizer_checkpoint.pt\n",
    "   269                                                               if conf[\"trainer\"][\"mode\"] == \"fsdp\":\n",
    "   270                                                                   shutil.copyfile(os.path.join(save_loc, \"model_checkpoint.pt\"),\n",
    "   271                                                                                   os.path.join(save_loc, \"backup_model_checkpoint.pt\"))\n",
    "   272\n",
    "   273                                                                   shutil.copyfile(os.path.join(save_loc, \"optimizer_checkpoint.pt\"),\n",
    "   274                                                                                   os.path.join(save_loc, \"backup_optimizer_checkpoint.pt\"))\n",
    "   275\n",
    "   276         1     125903.0 125903.0      0.0              logger.info(f\"Beginning epoch {epoch}\")\n",
    "   277\n",
    "   278                                                       # set the epoch in the dataset and sampler to ensure distribured randomness is handled correctly\n",
    "   279         1       4519.0   4519.0      0.0              if hasattr(train_loader, 'sampler') and hasattr(train_loader.sampler, 'set_epoch'):\n",
    "   280         1       3336.0   3336.0      0.0                  train_loader.sampler.set_epoch(epoch)  # Start a new forecast\n",
    "   281\n",
    "   282         1       1894.0   1894.0      0.0              if hasattr(train_loader.dataset, 'set_epoch'):\n",
    "   283         1       5100.0   5100.0      0.0                  train_loader.dataset.set_epoch(epoch)  # Ensure we don't start in the middle of a forecast epoch-over-epoch\n",
    "   284\n",
    "   285                                                       ############\n",
    "   286                                                       #\n",
    "   287                                                       # Train\n",
    "   288                                                       #\n",
    "   289                                                       ############\n",
    "   290\n",
    "   291         2        2e+12    9e+11     97.1              train_results = self.train_one_epoch(\n",
    "   292         1        251.0    251.0      0.0                  epoch,\n",
    "   293         1        240.0    240.0      0.0                  conf,\n",
    "   294         1        210.0    210.0      0.0                  train_loader,\n",
    "   295         1        361.0    361.0      0.0                  optimizer,\n",
    "   296         1        301.0    301.0      0.0                  train_criterion,\n",
    "   297         1        721.0    721.0      0.0                  scaler,\n",
    "   298         1        241.0    241.0      0.0                  scheduler,\n",
    "   299         1        211.0    211.0      0.0                  metrics\n",
    "   300                                                       )\n",
    "   301\n",
    "   302                                                       ############\n",
    "   303                                                       #\n",
    "   304                                                       # Validation\n",
    "   305                                                       #\n",
    "   306                                                       ############\n",
    "   307\n",
    "   308         1        681.0    681.0      0.0              if skip_validation:\n",
    "   309\n",
    "   310                                                           valid_results = train_results\n",
    "   311\n",
    "   312                                                       else:\n",
    "   313\n",
    "   314         2        5e+10    2e+10      2.7                  valid_results = self.validate(\n",
    "   315         1        581.0    581.0      0.0                      epoch,\n",
    "   316         1        251.0    251.0      0.0                      conf,\n",
    "   317         1        421.0    421.0      0.0                      valid_loader,\n",
    "   318         1        851.0    851.0      0.0                      valid_criterion,\n",
    "   319         1        210.0    210.0      0.0                      metrics\n",
    "   320                                                           )\n",
    "   321\n",
    "   322                                                       #################\n",
    "   323                                                       #\n",
    "   324                                                       # Save results\n",
    "   325                                                       #\n",
    "   326                                                       #################\n",
    "   327\n",
    "   328         1       9508.0   9508.0      0.0              results_dict[\"epoch\"].append(epoch)\n",
    "   329\n",
    "   330                                                       # Save metrics for select variables\n",
    "   331         1       1102.0   1102.0      0.0              required_metrics = [\"loss\", \"acc\", \"mae\", \"forecast_len\"]  # Base required metrics\n",
    "   332         1       4679.0   4679.0      0.0              if isinstance(save_metric_vars, list) and len(save_metric_vars) > 0:\n",
    "   333                                                           names = [key.replace(\"train_\", \"\") for key in train_results.keys() if any(var in key for var in save_metric_vars)]\n",
    "   334         1       1974.0   1974.0      0.0              elif isinstance(save_metric_vars, bool) and save_metric_vars:\n",
    "   335                                                           names = [key.replace(\"train_\", \"\") for key in train_results.keys()]\n",
    "   336                                                       else:\n",
    "   337         1        351.0    351.0      0.0                  names = []\n",
    "   338         1       4349.0   4349.0      0.0              names = list(set(names + required_metrics))\n",
    "   339\n",
    "   340         5       2294.0    458.8      0.0              for name in names:\n",
    "   341         4     168176.0  42044.0      0.0                  results_dict[f\"train_{name}\"].append(np.mean(train_results[f\"train_{name}\"]))\n",
    "   342         4       1182.0    295.5      0.0                  if skip_validation:\n",
    "   343                                                               continue\n",
    "   344         4     524352.0 131088.0      0.0                  results_dict[f\"valid_{name}\"].append(np.mean(valid_results[f\"valid_{name}\"]))\n",
    "   345         1       7454.0   7454.0      0.0              results_dict[\"lr\"].append(optimizer.param_groups[0][\"lr\"])\n",
    "   346\n",
    "   347                                                       # update the learning rate if epoch-by-epoch updates\n",
    "   348\n",
    "   349         1       1653.0   1653.0      0.0              if conf['trainer']['use_scheduler'] and conf['trainer']['scheduler']['scheduler_type'] in update_on_epoch:\n",
    "   350                                                           if conf['trainer']['scheduler']['scheduler_type'] == 'plateau':\n",
    "   351                                                               scheduler.step(results_dict[training_metric][-1])\n",
    "   352                                                           else:\n",
    "   353                                                               scheduler.step()\n",
    "   354\n",
    "   355                                                       # Create pandas df\n",
    "   356\n",
    "   357                                                       # Find the maximum length among all lists\n",
    "   358         1      11663.0  11663.0      0.0              max_len = max(len(lst) for lst in results_dict.values())\n",
    "   359\n",
    "   360                                                       # Prepend NaNs to lists that are shorter than max_len\n",
    "   361         1       1132.0   1132.0      0.0              padded_dict = OrderedDict()\n",
    "   362        11       5462.0    496.5      0.0              for key, lst in results_dict.items():\n",
    "   363        10       2903.0    290.3      0.0                  if len(lst) < max_len:\n",
    "   364                                                               padded_dict[key] = [np.nan] * (max_len - len(lst)) + lst\n",
    "   365                                                           else:\n",
    "   366        10       3947.0    394.7      0.0                      padded_dict[key] = lst\n",
    "   367\n",
    "   368         1    2262224.0    2e+06      0.0              df = pd.DataFrame.from_dict(padded_dict).reset_index()\n",
    "   369\n",
    "   370                                                       # Save the dataframe to disk\n",
    "   371\n",
    "   372         1        411.0    411.0      0.0              if trial:  # If using ECHO-opt, save to the trial_results directory\n",
    "   373                                                           df.to_csv(\n",
    "   374                                                               os.path.join(f\"{save_loc}\", \"trial_results\", f\"training_log_{trial.number}.csv\"),\n",
    "   375                                                               index=False,\n",
    "   376                                                           )\n",
    "   377                                                       else:\n",
    "   378         1   14437259.0    1e+07      0.0                  df.to_csv(os.path.join(f\"{save_loc}\", \"training_log.csv\"), index=False)\n",
    "   379\n",
    "   380                                                       ############\n",
    "   381                                                       #\n",
    "   382                                                       # Checkpoint\n",
    "   383                                                       #\n",
    "   384                                                       ############\n",
    "   385\n",
    "   386         1       1413.0   1413.0      0.0              if not trial:\n",
    "   387\n",
    "   388         1       3617.0   3617.0      0.0                  if conf[\"trainer\"][\"mode\"] != \"fsdp\":\n",
    "   389\n",
    "   390                                                               if self.rank == 0:\n",
    "   391\n",
    "   392                                                                   # Save the current model\n",
    "   393\n",
    "   394                                                                   logger.info(f\"Saving model, optimizer, grad scaler, and learning rate scheduler states to {save_loc}\")\n",
    "   395\n",
    "   396                                                                   state_dict = {\n",
    "   397                                                                       \"epoch\": epoch,\n",
    "   398                                                                       \"model_state_dict\": self.model.state_dict(),\n",
    "   399                                                                       \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "   400                                                                       'scheduler_state_dict': scheduler.state_dict() if conf[\"trainer\"][\"use_scheduler\"] else None,\n",
    "   401                                                                       'scaler_state_dict': scaler.state_dict()\n",
    "   402                                                                   }\n",
    "   403                                                                   torch.save(state_dict, f\"{save_loc}/checkpoint.pt\")\n",
    "   404\n",
    "   405                                                           else:\n",
    "   406\n",
    "   407         1     236507.0 236507.0      0.0                      logger.info(f\"Saving FSDP model, optimizer, grad scaler, and learning rate scheduler states to {save_loc}\")\n",
    "   408\n",
    "   409                                                               # Initialize the checkpoint I/O handler\n",
    "   410         1      12294.0  12294.0      0.0                      checkpoint_io = TorchFSDPCheckpointIO()\n",
    "   411\n",
    "   412                                                               # Save model and optimizer checkpoints\n",
    "   413         2  521726705.0    3e+08      0.0                      checkpoint_io.save_unsharded_model(\n",
    "   414         1       1172.0   1172.0      0.0                          self.model,\n",
    "   415         1      10400.0  10400.0      0.0                          os.path.join(save_loc, \"model_checkpoint.pt\"),\n",
    "   416         1        401.0    401.0      0.0                          gather_dtensor=True,\n",
    "   417         1        300.0    300.0      0.0                          use_safetensors=False,\n",
    "   418         1       1243.0   1243.0      0.0                          rank=self.rank\n",
    "   419                                                               )\n",
    "   420         2 2424341721.0    1e+09      0.1                      checkpoint_io.save_unsharded_optimizer(\n",
    "   421         1        291.0    291.0      0.0                          optimizer,\n",
    "   422         1       7645.0   7645.0      0.0                          os.path.join(save_loc, \"optimizer_checkpoint.pt\"),\n",
    "   423         1        572.0    572.0      0.0                          gather_dtensor=True,\n",
    "   424         1        400.0    400.0      0.0                          rank=self.rank\n",
    "   425                                                               )\n",
    "   426\n",
    "   427                                                               # Still need to save the scheduler and scaler states, just in another file for FSDP\n",
    "   428         1       2685.0   2685.0      0.0                      state_dict = {\n",
    "   429         1        211.0    211.0      0.0                          \"epoch\": epoch,\n",
    "   430         1       1973.0   1973.0      0.0                          'scheduler_state_dict': scheduler.state_dict() if conf[\"trainer\"][\"use_scheduler\"] else None,\n",
    "   431         1      12625.0  12625.0      0.0                          'scaler_state_dict': scaler.state_dict()\n",
    "   432                                                               }\n",
    "   433\n",
    "   434         1   22825879.0    2e+07      0.0                      torch.save(state_dict, os.path.join(save_loc, \"checkpoint.pt\"))\n",
    "   435\n",
    "   436                                                       # clear the cached memory from the gpu\n",
    "   437         1    9895808.0    1e+07      0.0              torch.cuda.empty_cache()\n",
    "   438         1  198765830.0    2e+08      0.0              gc.collect()\n",
    "   439         1       2504.0   2504.0      0.0              count += 1\n",
    "   440\n",
    "   441         1        510.0    510.0      0.0              if skip_validation:\n",
    "   442                                                           pass\n",
    "   443                                                       else:\n",
    "   444                                                           # Stop training if we have not improved after X epochs (stopping patience)\n",
    "   445         2      42734.0  21367.0      0.0                  best_epoch = [i for i, j in enumerate(results_dict[training_metric])\n",
    "   446         1        130.0    130.0      0.0                                if j == direction(results_dict[training_metric])][0]\n",
    "   447         1       1423.0   1423.0      0.0                  offset = epoch - best_epoch\n",
    "   448\n",
    "   449                                                           # ==================== #\n",
    "   450                                                           # backup the best epoch\n",
    "   451                                                           # ==================== #\n",
    "   452         1        781.0    781.0      0.0                  if offset == 0 and conf['trainer']['save_best_weights']:\n",
    "   453                                                               if self.rank == 0:\n",
    "   454                                                                   # checkpoint.pt\n",
    "   455                                                                   shutil.copyfile(\n",
    "   456                                                                       os.path.join(save_loc, \"checkpoint.pt\"),\n",
    "   457                                                                       os.path.join(save_loc, \"best_checkpoint.pt\")\n",
    "   458                                                                   )\n",
    "   459\n",
    "   460                                                                   # model_checkpoint.pt and optimizer_checkpoint.pt\n",
    "   461                                                                   if conf[\"trainer\"][\"mode\"] == \"fsdp\":\n",
    "   462                                                                       shutil.copyfile(\n",
    "   463                                                                           os.path.join(save_loc, \"model_checkpoint.pt\"),\n",
    "   464                                                                           os.path.join(save_loc, \"best_model_checkpoint.pt\")\n",
    "   465                                                                       )\n",
    "   466\n",
    "   467                                                                       shutil.copyfile(\n",
    "   468                                                                           os.path.join(save_loc, \"optimizer_checkpoint.pt\"),\n",
    "   469                                                                           os.path.join(save_loc, \"best_optimizer_checkpoint.pt\")\n",
    "   470                                                                       )\n",
    "   471\n",
    "   472                                                           # ==================== #\n",
    "   473                                                           # early stopping block\n",
    "   474                                                           # ==================== #\n",
    "   475         1       1844.0   1844.0      0.0                  if offset >= conf['trainer']['stopping_patience']:\n",
    "   476                                                               logger.info(\"Best {} were in epoch {}; current epoch is {}; early stopping.\".format(\n",
    "   477                                                                   training_metric, best_epoch, epoch))\n",
    "   478                                                               break\n",
    "   479\n",
    "   480                                                       # ==================== #\n",
    "   481                                                       # stop after one epoch\n",
    "   482                                                       # ==================== #\n",
    "   483         1       1263.0   1263.0      0.0              if 'stop_after_epoch' in conf['trainer']:\n",
    "   484                                                           if conf['trainer']['stop_after_epoch']:\n",
    "   485                                                               break\n",
    "   486\n",
    "   487         3       7885.0   2628.3      0.0          best_epoch = [\n",
    "   488         1        832.0    832.0      0.0              i for i, j in enumerate(results_dict[training_metric]) if j == direction(results_dict[training_metric])\n",
    "   489         1        140.0    140.0      0.0          ][0]\n",
    "   490\n",
    "   491         1       9288.0   9288.0      0.0          result = {k: v[best_epoch] for k, v in results_dict.items()}\n",
    "   492\n",
    "   493         1       1262.0   1262.0      0.0          if conf[\"trainer\"][\"mode\"] in [\"fsdp\", \"ddp\"]:\n",
    "   494         1     259852.0 259852.0      0.0              cleanup()\n",
    "   495\n",
    "   496         1        191.0    191.0      0.0          return result\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582a7f6-6ae8-4c43-a207-1fb21c1c026e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c325a4c-6a59-4110-9023-a1c84451a549",
   "metadata": {},
   "source": [
    "## `train_one_epoch`\n",
    "\n",
    "```python\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    61                                               def train_one_epoch(\n",
    "    62                                                   self,\n",
    "    63                                                   epoch,\n",
    "    64                                                   conf,\n",
    "    65                                                   trainloader,\n",
    "    66                                                   optimizer,\n",
    "    67                                                   criterion,\n",
    "    68                                                   scaler,\n",
    "    69                                                   scheduler,\n",
    "    70                                                   metrics\n",
    "    71                                               ):\n",
    "    72\n",
    "    73                                                   \"\"\"\n",
    "    74                                                   Trains the model for one epoch.\n",
    "    75\n",
    "    76                                                   Args:\n",
    "    77                                                       epoch (int): Current epoch number.\n",
    "    78                                                       conf (dict): Configuration dictionary containing training settings.\n",
    "    79                                                       trainloader (DataLoader): DataLoader for the training dataset.\n",
    "    80                                                       optimizer (torch.optim.Optimizer): Optimizer used for training.\n",
    "    81                                                       criterion (callable): Loss function used for training.\n",
    "    82                                                       scaler (torch.cuda.amp.GradScaler): Gradient scaler for mixed precision training.\n",
    "    83                                                       scheduler (torch.optim.lr_scheduler._LRScheduler): Learning rate scheduler.\n",
    "    84                                                       metrics (callable): Function to compute metrics for evaluation.\n",
    "    85\n",
    "    86                                                   Returns:\n",
    "    87                                                       dict: Dictionary containing training metrics and loss for the epoch.\n",
    "    88                                                   \"\"\"\n",
    "    89\n",
    "    90         1        892.0    892.0      0.0          batches_per_epoch = conf['trainer']['batches_per_epoch']\n",
    "    91         1        370.0    370.0      0.0          amp = conf['trainer']['amp']\n",
    "    92         1        652.0    652.0      0.0          distributed = True if conf[\"trainer\"][\"mode\"] in [\"fsdp\", \"ddp\"] else False\n",
    "    93         1        691.0    691.0      0.0          forecast_length = conf[\"data\"][\"forecast_len\"]\n",
    "    94\n",
    "    95                                                   # number of diagnostic variables\n",
    "    96         1       1142.0   1142.0      0.0          varnum_diag = len(conf[\"data\"]['diagnostic_variables'])\n",
    "    97\n",
    "    98                                                   # number of dynamic forcing + forcing + static\n",
    "    99         3       1131.0    377.0      0.0          static_dim_size = len(conf['data']['dynamic_forcing_variables']) + \\\n",
    "   100         1        290.0    290.0      0.0                            len(conf['data']['forcing_variables']) + \\\n",
    "   101         1        290.0    290.0      0.0                            len(conf['data']['static_variables'])\n",
    "   102\n",
    "   103                                                   # [Optional] Use the config option to set when to backprop\n",
    "   104         1        340.0    340.0      0.0          if 'backprop_on_timestep' in conf['data']:\n",
    "   105                                                       backprop_on_timestep = conf['data']['backprop_on_timestep']\n",
    "   106                                                   else:\n",
    "   107                                                       # If not specified in config, use the range 1 to forecast_len\n",
    "   108         1       1974.0   1974.0      0.0              backprop_on_timestep = list(range(0, conf['data']['forecast_len']+1+1))\n",
    "   109\n",
    "   110         1        551.0    551.0      0.0          assert forecast_length <= backprop_on_timestep[-1], (\n",
    "   111                                                       f\"forecast_length ({forecast_length + 1}) must not exceed the max value in backprop_on_timestep {backprop_on_timestep}\"\n",
    "   112                                                   )\n",
    "   113\n",
    "   114                                                   # update the learning rate if epoch-by-epoch updates that dont depend on a metric\n",
    "   115         1        341.0    341.0      0.0          if conf['trainer']['use_scheduler'] and conf['trainer']['scheduler']['scheduler_type'] == \"lambda\":\n",
    "   116                                                       scheduler.step()\n",
    "   117\n",
    "   118                                                   # set up a custom tqdm\n",
    "   119         1       3547.0   3547.0      0.0          if not isinstance(trainloader.dataset, IterableDataset):\n",
    "   120         1        180.0    180.0      0.0              batches_per_epoch = (\n",
    "   121         1      15410.0  15410.0      0.0                  batches_per_epoch if 0 < batches_per_epoch < len(trainloader) else len(trainloader)\n",
    "   122                                                       )\n",
    "   123\n",
    "   124         2     859685.0 429842.5      0.0          batch_group_generator = tqdm.tqdm(\n",
    "   125         1        401.0    401.0      0.0              range(batches_per_epoch), total=batches_per_epoch, leave=True\n",
    "   126                                                   )\n",
    "   127\n",
    "   128         1    6359749.0    6e+06      0.0          self.model.train()\n",
    "   129\n",
    "   130         1        842.0    842.0      0.0          dl = cycle(trainloader)\n",
    "   131\n",
    "   132         1       1142.0   1142.0      0.0          results_dict = defaultdict(list)\n",
    "   133\n",
    "   134        11       4652.0    422.9      0.0          for steps in range(batches_per_epoch):\n",
    "   135\n",
    "   136        10       4718.0    471.8      0.0              logs = {}\n",
    "   137        10    2160803.0 216080.3      0.0              loss = 0\n",
    "   138        10      11973.0   1197.3      0.0              stop_forecast = False\n",
    "   139        10   20803236.0    2e+06      0.0              y_pred = None  # Place holder that gets updated after first roll-out\n",
    "   140\n",
    "   141        20     576044.0  28802.2      0.0              with autocast(enabled=amp):\n",
    "   142\n",
    "   143       240     276366.0   1151.5      0.0                  while not stop_forecast:\n",
    "   144\n",
    "   145       240        2e+11    1e+09     14.6                      batch = next(dl)\n",
    "   146\n",
    "   147       480   12347402.0  25723.8      0.0                      for i, forecast_step in enumerate(batch[\"forecast_step\"]):\n",
    "   148                                                                   # if self.rank == 0:\n",
    "   149                                                                   #     logger.info(f\"i: {i}, forecast_step: {forecast_step}\")\n",
    "   150       240   12683168.0  52846.5      0.0                          if forecast_step == 1:\n",
    "   151                                                                       # Initialize x and x_surf with the first time step\n",
    "   152        10      17019.0   1701.9      0.0                              if \"x_surf\" in batch:\n",
    "   153                                                                           # combine x and x_surf\n",
    "   154                                                                           # input: (batch_num, time, var, level, lat, lon), (batch_num, time, var, lat, lon)\n",
    "   155                                                                           # output: (batch_num, var, time, lat, lon), 'x' first and then 'x_surf'\n",
    "   156        10  854855476.0    9e+07      0.1                                  x = concat_and_reshape(batch[\"x\"], batch[\"x_surf\"]).to(self.device)#.float()\n",
    "   157                                                                       else:\n",
    "   158                                                                           # no x_surf\n",
    "   159                                                                           x = reshape_only(batch[\"x\"]).to(self.device)#.float()\n",
    "   160\n",
    "   161                                                                   # add forcing and static variables (regardless of fcst hours)\n",
    "   162       240     294712.0   1228.0      0.0                          if 'x_forcing_static' in batch:\n",
    "   163\n",
    "   164                                                                       # (batch_num, time, var, lat, lon) --> (batch_num, var, time, lat, lon)\n",
    "   165       240  143398150.0 597492.3      0.0                              x_forcing_batch = batch['x_forcing_static'].to(self.device).permute(0, 2, 1, 3, 4)#.float()\n",
    "   166\n",
    "   167                                                                       # concat on var dimension\n",
    "   168       240   25076797.0 104486.7      0.0                              x = torch.cat((x, x_forcing_batch), dim=1)\n",
    "   169\n",
    "   170                                                                   # predict with the model\n",
    "   171       240        1e+12    5e+09     69.2                          y_pred = self.model(x)\n",
    "   172\n",
    "   173                                                                   # only load y-truth data if we intend to backprop (default is every step gets grads computed\n",
    "   174       240   16387437.0  68281.0      0.0                          if forecast_step in backprop_on_timestep:\n",
    "   175\n",
    "   176                                                                       # calculate rolling loss\n",
    "   177       240     235393.0    980.8      0.0                              if \"y_surf\" in batch:\n",
    "   178       240        2e+10    8e+07      1.2                                  y = concat_and_reshape(batch[\"y\"], batch[\"y_surf\"]).to(self.device)\n",
    "   179                                                                       else:\n",
    "   180                                                                           y = reshape_only(batch[\"y\"]).to(self.device)\n",
    "   181\n",
    "   182       240    1053344.0   4388.9      0.0                              if 'y_diag' in batch:\n",
    "   183\n",
    "   184                                                                           # (batch_num, time, var, lat, lon) --> (batch_num, var, time, lat, lon)\n",
    "   185                                                                           y_diag_batch = batch['y_diag'].to(self.device).permute(0, 2, 1, 3, 4)#.float()\n",
    "   186\n",
    "   187                                                                           # concat on var dimension\n",
    "   188                                                                           y = torch.cat((y, y_diag_batch), dim=1)\n",
    "   189\n",
    "   190       240 2488403762.0    1e+07      0.1                              loss = criterion(y.to(y_pred.dtype), y_pred).mean()\n",
    "   191\n",
    "   192                                                                       # track the loss\n",
    "   193       240   20136823.0  83903.4      0.0                              accum_log(logs, {'loss': loss.item()})\n",
    "   194\n",
    "   195                                                                       # compute gradients\n",
    "   196       240        2e+11    1e+09     13.8                              scaler.scale(loss).backward()\n",
    "   197\n",
    "   198       240     260156.0   1084.0      0.0                          if distributed:\n",
    "   199       240        1e+10    6e+07      0.8                              torch.distributed.barrier()\n",
    "   200\n",
    "   201                                                                   # stop after X steps\n",
    "   202       240    9798455.0  40826.9      0.0                          stop_forecast = batch['stop_forecast'][i]\n",
    "   203\n",
    "   204                                                                   # step-in-step-out\n",
    "   205       240    1534845.0   6395.2      0.0                          if x.shape[2] == 1:\n",
    "   206\n",
    "   207                                                                       # cut diagnostic vars from y_pred, they are not inputs\n",
    "   208       240     330691.0   1377.9      0.0                              if 'y_diag' in batch:\n",
    "   209                                                                           x = y_pred[:, :-varnum_diag, ...].detach()\n",
    "   210                                                                       else:\n",
    "   211       240    4160670.0  17336.1      0.0                                  x = y_pred.detach()\n",
    "   212\n",
    "   213                                                                   # multi-step in\n",
    "   214                                                                   else:\n",
    "   215                                                                       # static channels will get updated on next pass\n",
    "   216\n",
    "   217                                                                       if static_dim_size == 0:\n",
    "   218                                                                           x_detach = x[:, :, 1:, ...].detach()\n",
    "   219                                                                       else:\n",
    "   220                                                                           x_detach = x[:, :-static_dim_size, 1:, ...].detach()\n",
    "   221\n",
    "   222                                                                       # cut diagnostic vars from y_pred, they are not inputs\n",
    "   223                                                                       if 'y_diag' in batch:\n",
    "   224                                                                           x = torch.cat([x_detach,\n",
    "   225                                                                                          y_pred[:, :-varnum_diag, ...].detach()], dim=2)\n",
    "   226                                                                       else:\n",
    "   227                                                                           x = torch.cat([x_detach,\n",
    "   228                                                                                          y_pred.detach()], dim=2)\n",
    "   229\n",
    "   230       240    2552801.0  10636.7      0.0                      if stop_forecast:\n",
    "   231        10       2195.0    219.5      0.0                          break\n",
    "   232\n",
    "   233                                                           # scale, accumulate, backward\n",
    "   234\n",
    "   235        10       2286.0    228.6      0.0                  if distributed:\n",
    "   236        10    4020154.0 402015.4      0.0                      torch.distributed.barrier()\n",
    "   237\n",
    "   238        10 1225184451.0    1e+08      0.1                  scaler.step(optimizer)\n",
    "   239        10      67271.0   6727.1      0.0                  scaler.update()\n",
    "   240        10    7495549.0 749554.9      0.0                  optimizer.zero_grad()\n",
    "   241\n",
    "   242                                                       # Metrics\n",
    "   243                                                       # metrics_dict = metrics(y_pred.float(), y.float())\n",
    "   244        10 1077346971.0    1e+08      0.1              metrics_dict = metrics(y_pred, y)\n",
    "   245      2890    9220389.0   3190.4      0.0              for name, value in metrics_dict.items():\n",
    "   246      2880  205919969.0  71500.0      0.0                  value = torch.Tensor([value]).cuda(self.device, non_blocking=True)\n",
    "   247      2880    1160097.0    402.8      0.0                  if distributed:\n",
    "   248      2880  303978599.0 105548.1      0.0                      dist.all_reduce(value, dist.ReduceOp.AVG, async_op=False)\n",
    "   249      2880  192668871.0  66898.9      0.0                  results_dict[f\"train_{name}\"].append(value[0].item())\n",
    "   250\n",
    "   251        10     427673.0  42767.3      0.0              batch_loss = torch.Tensor([logs[\"loss\"]]).cuda(self.device)\n",
    "   252        10       3418.0    341.8      0.0              if distributed:\n",
    "   253        10     639531.0  63953.1      0.0                  dist.all_reduce(batch_loss, dist.ReduceOp.AVG, async_op=False)\n",
    "   254        10     305730.0  30573.0      0.0              results_dict[\"train_loss\"].append(batch_loss[0].item())\n",
    "   255        10      12675.0   1267.5      0.0              results_dict[\"train_forecast_len\"].append(forecast_length+1)\n",
    "   256\n",
    "   257        10     597321.0  59732.1      0.0              if not np.isfinite(np.mean(results_dict[\"train_loss\"])):\n",
    "   258                                                           print(results_dict[\"train_loss\"], batch[\"x\"].shape, batch[\"y\"].shape, batch[\"index\"])\n",
    "   259                                                           try:\n",
    "   260                                                               raise optuna.TrialPruned()\n",
    "   261                                                           except Exception as E:\n",
    "   262                                                               raise E\n",
    "   263\n",
    "   264                                                       # agg the results\n",
    "   265        20     125398.0   6269.9      0.0              to_print = \"Epoch: {} train_loss: {:.6f} train_acc: {:.6f} train_mae: {:.6f} forecast_len: {:.6f}\".format(\n",
    "   266        10       4217.0    421.7      0.0                  epoch,\n",
    "   267        10     182013.0  18201.3      0.0                  np.mean(results_dict[\"train_loss\"]),\n",
    "   268        10     131071.0  13107.1      0.0                  np.mean(results_dict[\"train_acc\"]),\n",
    "   269        10     115521.0  11552.1      0.0                  np.mean(results_dict[\"train_mae\"]),\n",
    "   270        10       3480.0    348.0      0.0                  forecast_length+1\n",
    "   271                                                       )\n",
    "   272        10      56299.0   5629.9      0.0              to_print += \" lr: {:.12f}\".format(optimizer.param_groups[0][\"lr\"])\n",
    "   273        10      15078.0   1507.8      0.0              if self.rank == 0:\n",
    "   274                                                           batch_group_generator.update(1)\n",
    "   275                                                           batch_group_generator.set_description(to_print)\n",
    "   276\n",
    "   277        10      14726.0   1472.6      0.0              if conf['trainer']['use_scheduler'] and conf['trainer']['scheduler']['scheduler_type'] in update_on_batch:\n",
    "   278                                                           scheduler.step()\n",
    "   279\n",
    "   280                                                   #  Shutdown the progbar\n",
    "   281         1     363450.0 363450.0      0.0          batch_group_generator.close()\n",
    "   282\n",
    "   283                                                   # clear the cached memory from the gpu\n",
    "   284         1  110189503.0    1e+08      0.0          torch.cuda.empty_cache()\n",
    "   285         1  226151814.0    2e+08      0.0          gc.collect()\n",
    "   286\n",
    "   287         1        902.0    902.0      0.0          return results_dict\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a476c05-b9a7-4979-b4de-7083e0098267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

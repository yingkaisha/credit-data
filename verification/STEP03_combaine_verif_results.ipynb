{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d56e0d15-21d8-49c0-aed0-0e36b5fefe52",
   "metadata": {},
   "source": [
    "# Combining verification results on individual days to a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92825f32-f2f0-4518-91cf-4b45873b57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import argparse\n",
    "from glob import glob\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37779f5-f1f7-424e-8ef1-74cdbcdf0cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.realpath('../libs/'))\n",
    "import verif_utils as vu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6104c698-762d-48b2-a92c-c8ed62865fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = os.path.realpath('verif_config.yml')\n",
    "\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44a3e66-25ac-431f-9655-1fe673eb6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['wxformer', 'IFS']\n",
    "# file name indices\n",
    "IND_max = 2192 # the ind of the last day\n",
    "INDs = np.arange(0, IND_max+40, 40) # qsub script creates files on every 40 days \n",
    "INDs[-1] = IND_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65fcce8-c40d-4c0b-9aa7-4c6a8c52815c",
   "metadata": {},
   "source": [
    "## 2018-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a86199-f3bf-4208-b975-e1a5655666e3",
   "metadata": {},
   "source": [
    "### Check NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f9e174-cbe3-497b-9c6c-2336dc42bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIF = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a471d67-20d4-4cc6-99b2-5af59dc9d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    # file names to load\n",
    "    verif_lead_range = conf[model_name]['verif_lead_range']\n",
    "    path_RMSE_verif = conf[model_name]['save_loc_verif']+'combined_rmse_{:04d}_{:04d}_{:03d}h_{:03d}h_{}.nc'\n",
    "\n",
    "    # file names to save\n",
    "    path_RMSE_save = conf[model_name]['save_loc_verif']+'RMSE_{:03d}h_{:03d}h_{}.nc'\n",
    "    \n",
    "    # load xarray.Dataset and merge all verified days\n",
    "    RMSE_verif = []\n",
    "\n",
    "    for i, ind_start in enumerate(INDs[:-1]):\n",
    "        ind_end = INDs[i+1]\n",
    "    \n",
    "        filename = path_RMSE_verif.format(ind_start, ind_end, verif_lead_range[0], verif_lead_range[-1], model_name)\n",
    "        ds_verf_temp = xr.open_dataset(filename)\n",
    "        RMSE_verif.append(ds_verf_temp)\n",
    "    \n",
    "    # merge by concat\n",
    "    ds_RMSE_verif = xr.concat(RMSE_verif, dim='days')\n",
    "\n",
    "    # save to one dictionary for some checking\n",
    "    VERIF['{}_RMSE'.format(model_name)] = ds_RMSE_verif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748fc6c8-0cec-411a-92d3-449b3a0760b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if see NaN, find its indices\n",
    "for var_name in ['U500', 'V500', 'T500', 'Q500', 'Z500', 't2m', 'SP']:\n",
    "    test = np.mean(np.array(VERIF['wxformer_RMSE']['V500']), axis=1)\n",
    "    ind_found = np.argwhere(np.isnan(test))\n",
    "\n",
    "if len(ind_found) == 0:\n",
    "    print('No NaN found')\n",
    "else:\n",
    "    model_name = 'wxformer'\n",
    "    filename_OURS = sorted(glob(conf[model_name]['save_loc_gather']+'*.nc'))\n",
    "    \n",
    "    year_range = conf[model_name]['year_range']\n",
    "    years_pick = np.arange(year_range[0], year_range[1]+1, 1).astype(str)\n",
    "    filename_OURS = [fn for fn in filename_OURS if any(year in fn for year in years_pick)]\n",
    "\n",
    "    for i in range(len(ind_found)):\n",
    "        ind_check = ind_found[i][0]\n",
    "        print('bad file: {}'.format(filename_OURS[ind_check]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640174f5-28ad-41c5-b971-463aac3241f8",
   "metadata": {},
   "source": [
    "### Save RMSE and ACC as netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb1389-45ed-4d1e-860d-afd5379b8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIF = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae4c61-c666-465c-9cd7-82ee263b52b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    # file names to load\n",
    "    verif_lead_range = conf[model_name]['verif_lead_range']\n",
    "    path_ACC_verif = conf[model_name]['save_loc_verif']+'combined_acc_{:04d}_{:04d}_{:03d}h_{:03d}h_{}.nc'\n",
    "    path_RMSE_verif = conf[model_name]['save_loc_verif']+'combined_rmse_{:04d}_{:04d}_{:03d}h_{:03d}h_{}.nc'\n",
    "\n",
    "    # file names to save\n",
    "    path_ACC_save = conf[model_name]['save_loc_verif']+'ACC_{:03d}h_{:03d}h_{}.nc'\n",
    "    path_RMSE_save = conf[model_name]['save_loc_verif']+'RMSE_{:03d}h_{:03d}h_{}.nc'\n",
    "    \n",
    "    # load xarray.Dataset and merge all verified days\n",
    "    ACC_verif = []\n",
    "    RMSE_verif = []\n",
    "\n",
    "    for i, ind_start in enumerate(INDs[:-1]):\n",
    "        ind_end = INDs[i+1]\n",
    "        filename = path_ACC_verif.format(ind_start, ind_end, verif_lead_range[0], verif_lead_range[-1], model_name)\n",
    "        ds_verf_temp = xr.open_dataset(filename)\n",
    "        ACC_verif.append(ds_verf_temp)\n",
    "    \n",
    "        filename = path_RMSE_verif.format(ind_start, ind_end, verif_lead_range[0], verif_lead_range[-1], model_name)\n",
    "        ds_verf_temp = xr.open_dataset(filename)\n",
    "        RMSE_verif.append(ds_verf_temp)\n",
    "    \n",
    "    # merge by concat\n",
    "    ds_ACC_verif = xr.concat(ACC_verif, dim='days')\n",
    "    ds_RMSE_verif = xr.concat(RMSE_verif, dim='days')\n",
    "\n",
    "    # save to one dictionary for some checking\n",
    "    VERIF['{}_ACC'.format(model_name)] = ds_ACC_verif\n",
    "    VERIF['{}_RMSE'.format(model_name)] = ds_RMSE_verif\n",
    "\n",
    "    # save to nc\n",
    "    save_name_ACC = path_ACC_save.format(verif_lead_range[0], verif_lead_range[-1], model_name)\n",
    "    #ds_ACC_verif.to_netcdf(save_name_ACC)\n",
    "    print('Save to {}'.format(save_name_ACC))\n",
    "    \n",
    "    save_name_RMSE = path_RMSE_save.format(verif_lead_range[0], verif_lead_range[-1], model_name)\n",
    "    #ds_RMSE_verif.to_netcdf(save_name_RMSE)\n",
    "    print('Save to {}'.format(save_name_RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb4172-48d7-4c37-bae1-3affbe72398a",
   "metadata": {},
   "source": [
    "### Get ready for data visualizaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd32a2-cc27-491e-9a2c-dc400676c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['wxformer', 'IFS']\n",
    "varnames_plot = ['U500', 'V500', 'T500', 'Q500', 'Z500', 't2m', 'SP']\n",
    "\n",
    "PLOT_data = {}\n",
    "\n",
    "for var in varnames_plot:\n",
    "    for model_name in model_names:\n",
    "        np_RMSE = np.array(VERIF['{}_RMSE'.format(model_name)][var])\n",
    "        np_ACC = np.array(VERIF['{}_ACC'.format(model_name)][var])\n",
    "\n",
    "        # mean scores\n",
    "        PLOT_data['RMSE_{}_{}_mean'.format(model_name, var)] = np.mean(np_RMSE, axis=0)\n",
    "        PLOT_data['ACC_{}_{}_mean'.format(model_name, var)] = np.nanmean(np_ACC, axis=0)\n",
    "\n",
    "        # 95th CIs\n",
    "        PLOT_data['RMSE_{}_{}_95p'.format(model_name, var)] = np.quantile(np_RMSE, 0.95, axis=0)\n",
    "        PLOT_data['ACC_{}_{}_95p'.format(model_name, var)] = np.quantile(np_ACC, 0.95, axis=0)\n",
    "\n",
    "        PLOT_data['RMSE_{}_{}_05p'.format(model_name, var)] = np.quantile(np_RMSE, 0.05, axis=0)\n",
    "        PLOT_data['ACC_{}_{}_05p'.format(model_name, var)] = np.quantile(np_ACC, 0.05, axis=0)\n",
    "\n",
    "# Save\n",
    "np.save('/glade/derecho/scratch/ksha/CREDIT/verif/PLOT_data/scores_CREDIT_arXiv_2024_LARGE.npy', PLOT_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0ae165-3ebf-44b3-85c9-bee227849383",
   "metadata": {},
   "source": [
    "## Separate by years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087b058-8326-46a4-8573-cbe60f868ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    # file names to load\n",
    "    verif_lead_range = conf[model_name]['verif_lead_range']\n",
    "    path_ACC_verif = conf[model_name]['save_loc_verif']+'combined_acc_{:04d}_{:04d}_{:03d}h_{:03d}h_{}.nc'\n",
    "    path_RMSE_verif = conf[model_name]['save_loc_verif']+'combined_rmse_{:04d}_{:04d}_{:03d}h_{:03d}h_{}.nc'\n",
    "\n",
    "    # file names to save\n",
    "    path_ACC_save = conf[model_name]['save_loc_verif']+'ACC_{:03d}h_{:03d}h_{}_y{}.nc'\n",
    "    path_RMSE_save = conf[model_name]['save_loc_verif']+'RMSE_{:03d}h_{:03d}h_{}_y{}.nc'\n",
    "\n",
    "    # load xarray.Dataset and merge all verified days\n",
    "    ACC_verif = []\n",
    "    RMSE_verif = []\n",
    "\n",
    "    for i, ind_start in enumerate(INDs[:-1]):\n",
    "        ind_end = INDs[i+1]\n",
    "        filename = path_ACC_verif.format(ind_start, ind_end, verif_lead_range[0], verif_lead_range[-1], model_name)\n",
    "        ds_verf_temp = xr.open_dataset(filename)\n",
    "        ACC_verif.append(ds_verf_temp)\n",
    "    \n",
    "        filename = path_RMSE_verif.format(ind_start, ind_end, verif_lead_range[0], verif_lead_range[-1], model_name)\n",
    "        ds_verf_temp = xr.open_dataset(filename)\n",
    "        RMSE_verif.append(ds_verf_temp)\n",
    "\n",
    "    # merge by concat\n",
    "    ds_ACC_verif = xr.concat(ACC_verif, dim='days')\n",
    "    ds_RMSE_verif = xr.concat(RMSE_verif, dim='days')\n",
    "\n",
    "    # get indices when years are changed\n",
    "    doy = np.array(ds_ACC_verif.dayofyear)[:, 0]\n",
    "    ind_year_change = np.argwhere(np.diff(doy)<0)[:, 0]\n",
    "    ind_year_change = list(np.concatenate((np.array([0,]), ind_year_change+1, np.array([len(doy)])), axis=0))\n",
    "    \n",
    "    for i_year, year in enumerate([2018, 2019, 2020]):\n",
    "    \n",
    "        # save to one dictionary for some checking\n",
    "        VERIF['{}_ACC_{}'.format(model_name, year)] = ds_ACC_verif.isel(days=slice(ind_year_change[i_year], \n",
    "                                                                                   ind_year_change[i_year+1]))\n",
    "        VERIF['{}_RMSE_{}'.format(model_name, year)] = ds_RMSE_verif.isel(days=slice(ind_year_change[i_year], \n",
    "                                                                                   ind_year_change[i_year+1]))\n",
    "    \n",
    "        # save to nc\n",
    "        save_name_ACC = path_ACC_save.format(verif_lead_range[0], verif_lead_range[-1], model_name, year)\n",
    "        #ds_ACC_verif.to_netcdf(save_name_ACC)\n",
    "        print('Save to {}'.format(save_name_ACC))\n",
    "        \n",
    "        save_name_RMSE = path_RMSE_save.format(verif_lead_range[0], verif_lead_range[-1], model_name, year)\n",
    "        ds_RMSE_verif.to_netcdf(save_name_RMSE)\n",
    "        print('Save to {}'.format(save_name_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e221b-3c9d-4297-b1d4-2444936119a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['wxformer', 'IFS']\n",
    "varnames_plot = ['U500', 'V500', 'T500', 'Q500', 'Z500', 't2m', 'SP']\n",
    "\n",
    "PLOT_data = {}\n",
    "\n",
    "for i_year, year in enumerate([2018, 2019, 2020]):\n",
    "    for var in varnames_plot:\n",
    "        for model_name in model_names:\n",
    "            np_RMSE = np.array(VERIF['{}_RMSE_{}'.format(model_name, year)][var])\n",
    "            np_ACC = np.array(VERIF['{}_ACC_{}'.format(model_name, year)][var])\n",
    "    \n",
    "            # mean scores\n",
    "            PLOT_data['RMSE_{}_{}_{}_mean'.format(model_name, var, year)] = np.mean(np_RMSE, axis=0)\n",
    "            PLOT_data['ACC_{}_{}_{}_mean'.format(model_name, var, year)] = np.nanmean(np_ACC, axis=0)\n",
    "    \n",
    "            # 95th CIs\n",
    "            PLOT_data['RMSE_{}_{}_{}_95p'.format(model_name, var, year)] = np.quantile(np_RMSE, 0.95, axis=0)\n",
    "            PLOT_data['ACC_{}_{}_{}_95p'.format(model_name, var, year)] = np.quantile(np_ACC, 0.95, axis=0)\n",
    "    \n",
    "            PLOT_data['RMSE_{}_{}_{}_05p'.format(model_name, var, year)] = np.quantile(np_RMSE, 0.05, axis=0)\n",
    "            PLOT_data['ACC_{}_{}_{}_05p'.format(model_name, var, year)] = np.quantile(np_ACC, 0.05, axis=0)\n",
    "\n",
    "# Save\n",
    "np.save('/glade/derecho/scratch/ksha/CREDIT/verif/PLOT_data/scores_CREDIT_arXiv_2024_LARGE_by_year.npy', PLOT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc4e5f9-f88c-45eb-8d0b-9dae3d2a1c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f90f1d6-3ad1-4420-ade9-8670ac2d049a",
   "metadata": {},
   "source": [
    "# Compute residual normalization constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97dd4b6-069c-42ca-9231-e3edd65ea615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import time\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740fae7-f9bc-4bad-bf72-0556d7def51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from credit.data import get_forward_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a67729-565a-43ae-b5ea-4ae445283e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.realpath('../libs/'))\n",
    "import preprocess_utils as pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b57302-f80b-4314-9db5-cb29dd44f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = os.path.realpath('data_config_6h.yml')\n",
    "\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d49a0d-daa2-4009-8483-c1dd08f96fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b15a2c-6c07-469a-9f59-85886da81f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = 'U'\n",
    "ind_level = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d339c-020f-49bf-80d7-41276c03cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pu.residual_zscore_var(conf, varname, ind_level=ind_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662478c-14bc-47c1-9706-d905968e36c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8ddd2-fa8a-4696-b3ea-5480928ba8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = 'U500'\n",
    "ind_level = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93afe60e-afdc-4c21-ad64-00ff3d19bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pu.residual_zscore_var(conf, varname, ind_level=ind_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657600e-4e7b-45a9-9aaf-767d462aab02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2a827-ae93-4ee2-a2d0-c677fa3b6df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91789936-0dc0-421a-b67e-33affca8fee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f3dca2b-deb1-4635-87b4-90600a99cc5f",
   "metadata": {},
   "source": [
    "## `xr.apply_ufunc(np.diff)` vs `np.diff` directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cac813-8c41-4e39-a87a-94e13c29efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = list_ds_train[0]\n",
    "if ind_level is not None:\n",
    "    ds = ds.isel(level=ind_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18db737-5b0e-4bfe-87f9-217684d7500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.isel(time=slice(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8dc317-852b-46d2-9ab9-e9c46aa5eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_diff = xr.apply_ufunc(\n",
    "    np.diff,\n",
    "    ds[varname],\n",
    "    input_core_dims=[['time']],\n",
    "    output_core_dims=[['time_diff']],  # Change this to a new dimension name\n",
    "    vectorize=True,\n",
    "    dask='allowed',\n",
    "    output_dtypes=[ds[varname].dtype]\n",
    ")\n",
    "\n",
    "ds_out = var_diff.to_dataset(name='{}_diff'.format(varname))\n",
    "\n",
    "ds_out = ds_out.assign_coords(\n",
    "    time_diff=ds_out['time_diff'])\n",
    "\n",
    "ds_out = ds_out.transpose(\"time_diff\", \"latitude\", \"longitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591df38e-091d-425f-9faf-5bf5cee1aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1 = np.array(ds_out['U_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b0649-e85e-481a-a997-81874731e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff2 = np.diff(np.array(ds['U']), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e97ac-8b88-4e1e-80a6-18606d9d662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(diff1 - diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb9e2f-3c5b-4b43-8945-a551bdb2c0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f6b87-97fb-4030-a779-8dae39048bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames = sorted(glob(conf['zscore'][varname]))\n",
    "\n",
    "# year_range = conf['zscore']['years_range']\n",
    "# train_years = [str(year) for year in range(year_range[0], year_range[1])]\n",
    "# train_files = [file for file in filenames if any(year in file for year in train_years)]\n",
    "\n",
    "# list_ds_train = []\n",
    "\n",
    "# for fn in train_files:\n",
    "#     list_ds_train.append(get_forward_data(fn))\n",
    "    \n",
    "# # ------------------------------------------------------------------------------------ #\n",
    "# ds_example = list_ds_train[0][varname]\n",
    "# var_shape = ds_example.shape\n",
    "\n",
    "# N_grids = var_shape[-1] * var_shape[-2]\n",
    "# mean_std_save = np.empty((2,))\n",
    "# mean_std_save.fill(np.nan)\n",
    "\n",
    "# for i_fn, ds in enumerate(list_ds_train):\n",
    "#     # ===================================================================== #\n",
    "#     # apply np.diff\n",
    "#     var_diff = xr.apply_ufunc(\n",
    "#         np.diff,\n",
    "#         ds[varname],\n",
    "#         input_core_dims=[['time']],\n",
    "#         output_core_dims=[['time_diff']],  # Change this to a new dimension name\n",
    "#         vectorize=True,\n",
    "#         dask='allowed',\n",
    "#         output_dtypes=[ds[varname].dtype]\n",
    "#     )\n",
    "    \n",
    "#     ds_out = var_diff.to_dataset(name='{}_diff'.format(varname))\n",
    "    \n",
    "#     ds_out = ds_out.assign_coords(\n",
    "#         time_diff=ds_out['time_diff'])\n",
    "    \n",
    "#     ds_out = ds_out.transpose(\"time_diff\", \"latitude\", \"longitude\")\n",
    "    \n",
    "#     # ===================================================================== #\n",
    "#     # compute the mean and std from the np.diff result\n",
    "    \n",
    "#     ds_subset = ds_out['{}_diff'.format(varname)]\n",
    "    \n",
    "#     # get mean and var for the current year\n",
    "#     mean_current_yr = float(ds_subset.mean())\n",
    "#     var_current_yr = float(ds_subset.var())\n",
    "#     L = len(ds_subset) * N_grids\n",
    "    \n",
    "#     print('{} - {}'.format(mean_current_yr, var_current_yr))\n",
    "        \n",
    "#     if i_fn == 0:\n",
    "#         # if it is the first year, pass current year to the combined \n",
    "#         mean_std_save[0] = mean_current_yr\n",
    "#         mean_std_save[1] = var_current_yr\n",
    "#         N_samples = L\n",
    "        \n",
    "#     else:\n",
    "#         # https://math.stackexchange.com/questions/2971315/how-do-i-combine-standard-deviations-of-two-groups\n",
    "#         mean_new = (L * mean_current_yr + N_samples * mean_std_save[0]) / (L + N_samples)\n",
    "#         var_new = ((L - 1) * var_current_yr + (N_samples - 1) * mean_std_save[1]) / (L + N_samples - 1)\n",
    "#         var_new_adjust = (L * N_samples * (mean_current_yr - mean_std_save[0])**2) / (L + N_samples) / (L + N_samples -1)\n",
    "        \n",
    "#         mean_std_save[0] = mean_new\n",
    "#         mean_std_save[1] = var_new + var_new_adjust\n",
    "#         N_samples = N_samples + L\n",
    "        \n",
    "#         print('{} - {}'.format(mean_std_save[0], mean_std_save[1]))\n",
    "\n",
    "# save_name = conf['zscore']['save_loc'] + '{}_residual_mean_std_{}.npy'.format(conf['zscore']['prefix'], varname)\n",
    "# print('Save to {}'.format(save_name))\n",
    "# # np.save(save_name, mean_std_save)\n",
    "\n",
    "# start_time = time.time()\n",
    "# main()\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

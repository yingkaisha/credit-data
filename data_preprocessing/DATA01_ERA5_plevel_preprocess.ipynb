{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa08066-4289-4781-902c-7e83e244857d",
   "metadata": {},
   "source": [
    "# Pre-process ERA5 pressure level data for CREDIT\n",
    "\n",
    "This notebook provides methods on gathering ERA5 pressure level data from NCAR/RDA and ARCO-ERA5. The RDA data requires internal access of the glade file system at NCAR.\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "* **Pressure-level analysis (RDA)**\n",
    "    * geopotential, u_component_of_wind, v_component_of_wind, temperature, specific_humidity\n",
    "* **Single-level analysis (RDA)**\n",
    "    * surface_pressure, mean_sea_level_pressure\n",
    "    * sea_surface_temperature, skin_temperature, 2m_temperature,\n",
    "    * 10m_u_component_of_wind, 10m_v_component_of_wind, total_cloud_cover\n",
    "* **Single-level forecasts (ARCO)**\n",
    "    * total_precipitation, evaporation\n",
    "    * top_net_solar_radiation, top_net_thermal_radiation\n",
    "    * surface_net_solar_radiation, surface_net_thermal_radiation, surface_latent_heat_flux, surface_sensible_heat_flux\n",
    "\n",
    "**References**\n",
    "\n",
    "* NCAR/RDA\n",
    "    * [ERA5 Reanalysis (0.25 Degree Latitude-Longitude Grid)](https://rda.ucar.edu/datasets/d633000/)\n",
    "    * glade storage: `/glade/campaign/collections/rda/data/d633000/`\n",
    "* ARCO-ERA5\n",
    "    * [Google Cloud storage](https://console.cloud.google.com/storage/browser/gcp-public-data-arco-era5)\n",
    "    * [Project page at GitHub](https://github.com/google-research/arco-era5)\n",
    "    * Complete hourly file: `gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70332162-6c47-4172-a003-326059f10045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import dask\n",
    "import zarr\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from dask.utils import SerializableLock\n",
    "\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "sys.path.insert(0, os.path.realpath('../libs/'))\n",
    "import verif_utils as vu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f217f9a-f8a5-4798-b055-c26c6f0d7fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "# from dask.distributed import Client\n",
    "# from dask_jobqueue import PBSCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa740e32-0024-4dec-b2c9-ce7c7f92f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068fbd7-18c4-496a-a1f7-c63f26c59544",
   "metadata": {},
   "source": [
    "## Upper-air variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e804cc7b-5116-4492-b772-03dec0ae2f34",
   "metadata": {},
   "source": [
    "**NCAR/RDA**\n",
    "\n",
    "An example of file listing at `/glade/campaign/collections/rda/data/d633000/e5.oper.an.pl/197901`\n",
    "```\n",
    "e5.oper.an.pl.128_060_pv.ll025sc.1979010100_1979010123.nc    \n",
    "e5.oper.an.pl.128_132_v.ll025uv.1979010100_1979010123.nc   \n",
    "e5.oper.an.pl.128_203_o3.ll025sc.1979010100_1979010123.nc\n",
    "e5.oper.an.pl.128_075_crwc.ll025sc.1979010100_1979010123.nc  \n",
    "e5.oper.an.pl.128_133_q.ll025sc.1979010100_1979010123.nc\n",
    "e5.oper.an.pl.128_246_clwc.ll025sc.1979010100_1979010123.nc\n",
    "e5.oper.an.pl.128_076_cswc.ll025sc.1979010100_1979010123.nc  \n",
    "e5.oper.an.pl.128_135_w.ll025sc.1979010100_1979010123.nc   \n",
    "e5.oper.an.pl.128_247_ciwc.ll025sc.1979010100_1979010123.nc\n",
    "e5.oper.an.pl.128_129_z.ll025sc.1979010100_1979010123.nc     \n",
    "e5.oper.an.pl.128_138_vo.ll025sc.1979010100_1979010123.nc  \n",
    "e5.oper.an.pl.128_248_cc.ll025sc.1979010100_1979010123.nc\n",
    "e5.oper.an.pl.128_130_t.ll025sc.1979010100_1979010123.nc     \n",
    "e5.oper.an.pl.128_155_d.ll025sc.1979010100_1979010123.nc\n",
    "e5.oper.an.pl.128_131_u.ll025uv.1979010100_1979010123.nc     \n",
    "e5.oper.an.pl.128_157_r.ll025sc.1979010100_1979010123.nc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77331573-6b69-4a51-83ca-81c25b57654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2000\n",
    "N_days = 366 if year % 4 == 0 else 365\n",
    "\n",
    "config_name = os.path.realpath('data_config_6h.yml')\n",
    "\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70581b03-5fa6-48b0-bb64-116b0b23e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "compress = zarr.Blosc(cname='zstd', clevel=1, shuffle=zarr.Blosc.SHUFFLE, blocksize=0)\n",
    "\n",
    "\n",
    "chunk_size_4d = dict(chunks=(conf['RDA']['chunk_size_4d']['time'],\n",
    "                                 conf['RDA']['chunk_size_4d']['level'],\n",
    "                                 conf['RDA']['chunk_size_4d']['latitude'],\n",
    "                                 conf['RDA']['chunk_size_4d']['longitude']))\n",
    "\n",
    "dict_encoding = {}\n",
    "\n",
    "for i_var, var in enumerate(conf['RDA']['varname_upper_air']):\n",
    "    dict_encoding[var] = {'compressor': compress, **chunk_size_4d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5107f5c1-a8e0-461b-8a26-ba94f22ec93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the file cache size\n",
    "xr.set_options(file_cache_maxsize=500)\n",
    "# lock for safe parallel access\n",
    "netcdf_lock = SerializableLock()\n",
    "\n",
    "# all days within a year\n",
    "start_time = datetime(year, 1, 1, 0, 0)\n",
    "dt_list = [start_time + timedelta(days=i) for i in range(N_days)]\n",
    "\n",
    "# upper-air var names\n",
    "varnames = list(conf['RDA']['varname_upper_air'].values())\n",
    "\n",
    "ds_list = []\n",
    "\n",
    "for i_day, dt in enumerate(dt_list):\n",
    "    # file source info\n",
    "    base_dir = dt.strftime(conf['RDA']['source']['anpl_format'])\n",
    "    dt_pattern = dt.strftime(conf['RDA']['source']['anpl_dt_pattern_format'])\n",
    "\n",
    "    # get upper-air vars\n",
    "    filename_collection = [glob(base_dir + f'*{var}*{dt_pattern}*')[0] for var in varnames]\n",
    "    \n",
    "    if len(filename_collection) != len(varnames):\n",
    "        raise ValueError(f'Year {year}, day {day_idx} has incomplete files')\n",
    "    \n",
    "    # Open with a lock to avoid race conditions when accessing files\n",
    "    ds = xr.open_mfdataset(filename_collection, combine='by_coords', parallel=True, lock=netcdf_lock)\n",
    "\n",
    "    # drop useless var\n",
    "    ds = ds.drop_vars('utc_date', errors='ignore')\n",
    "\n",
    "    # hourly --> 6 hourly\n",
    "    ds = ds.isel(time=slice(0, -1, 6))\n",
    "    \n",
    "    #  chunking\n",
    "    ds = ds.chunk(conf['RDA']['chunk_size_4d'])\n",
    "    ds_list.append(ds)\n",
    "    \n",
    "# concatenate\n",
    "ds_yearly = xr.concat(ds_list, dim='time')\n",
    "\n",
    "# save to zarr\n",
    "base_dir = conf['RDA']['save_loc'] + 'upper_air/' \n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "save_name = base_dir + conf['RDA']['prefix'] + '_upper_air_{}.zarr'.format(year)\n",
    "\n",
    "# ds_yearly.to_zarr(save_name, mode='w', consolidated=True, compute=True, encoding=dict_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a15062-1068-4ef3-bfda-843470fbdf96",
   "metadata": {},
   "source": [
    "### Single-level variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf57dbf-a2f6-4057-8356-99bfccb84152",
   "metadata": {},
   "source": [
    "An example of file listing at `/glade/campaign/collections/rda/data/d633000/e5.oper.an.sfc/197901`\n",
    "\n",
    "```\n",
    "e5.oper.an.sfc.128_015_aluvp.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_167_2t.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_016_aluvd.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_168_2d.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_017_alnip.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_170_stl2.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_018_alnid.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_183_stl3.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_031_ci.ll025sc.1979010100_1979013123.nc     e5.oper.an.sfc.128_186_lcc.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_032_asn.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.128_187_mcc.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_033_rsn.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.128_188_hcc.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_034_sstk.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.128_198_src.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_035_istl1.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_206_tco3.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_036_istl2.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_229_iews.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_037_istl3.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_230_inss.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_038_istl4.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_231_ishf.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_039_swvl1.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_232_ie.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_040_swvl2.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_235_skt.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_041_swvl3.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_236_stl4.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_042_swvl4.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_238_tsn.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_059_cape.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.128_243_fal.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_066_lailv.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_244_fsr.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_067_laihv.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_245_flsr.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_078_tclw.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.228_008_lmlt.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_079_tciw.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.228_009_lmld.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_134_sp.ll025sc.1979010100_1979013123.nc     e5.oper.an.sfc.228_010_lblt.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_136_tcw.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.228_011_ltlt.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_137_tcwv.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.228_012_lshf.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_139_stl1.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.228_013_lict.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_141_sd.ll025sc.1979010100_1979013123.nc     e5.oper.an.sfc.228_014_licd.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_148_chnk.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.228_089_tcrw.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_151_msl.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.228_090_tcsw.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_159_blh.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.228_131_u10n.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_164_tcc.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.228_132_v10n.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_165_10u.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.228_246_100u.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_166_10v.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.228_247_100v.ll025sc.1979010100_1979013123.nc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcec2c2f-f769-4a5c-a70e-fca40d672c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2000\n",
    "N_months = 12\n",
    "\n",
    "config_name = os.path.realpath('data_config_6h.yml')\n",
    "\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d07006-5a2a-4976-aafc-124c85555333",
   "metadata": {},
   "outputs": [],
   "source": [
    "compress = zarr.Blosc(cname='zstd', clevel=1, shuffle=zarr.Blosc.SHUFFLE, blocksize=0)\n",
    "\n",
    "\n",
    "chunk_size_3d = dict(chunks=(conf['RDA']['chunk_size_3d']['time'],\n",
    "                             conf['RDA']['chunk_size_3d']['latitude'],\n",
    "                             conf['RDA']['chunk_size_3d']['longitude']))\n",
    "\n",
    "dict_encoding = {}\n",
    "\n",
    "for i_var, var in enumerate(conf['RDA']['varname_single']):\n",
    "    dict_encoding[var] = {'compressor': compress, **chunk_size_3d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "043142a3-c181-4d89-bd3f-8c9f65769887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the file cache size\n",
    "xr.set_options(file_cache_maxsize=500)\n",
    "# lock for safe parallel access\n",
    "netcdf_lock = SerializableLock()\n",
    "\n",
    "# all days within a year\n",
    "start_time = datetime(year, 1, 1, 0, 0)\n",
    "dt_list = [start_time + relativedelta(months=i) for i in range(N_months)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1695721b-6009-4917-9579-7cd089926a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var names\n",
    "varnames = list(conf['RDA']['varname_single'].values())\n",
    "\n",
    "ds_list = []\n",
    "\n",
    "for i_mon, dt in enumerate(dt_list):\n",
    "    # file source info\n",
    "    base_dir = dt.strftime(conf['RDA']['source']['ansfc_format'])\n",
    "\n",
    "    first_day = datetime(year, dt.month, 1)\n",
    "    last_day = datetime(year, dt.month, calendar.monthrange(year, dt.month)[1])\n",
    "    \n",
    "    dt_pattern = dt.strftime(conf['RDA']['source']['ansfc_dt_pattern_format'])\n",
    "    dt_pattern = dt_pattern.format(first_day.day, last_day.day)\n",
    "    \n",
    "    # get upper-air vars\n",
    "    filename_collection = [glob(base_dir + f'*{var}*{dt_pattern}*')[0] for var in varnames]\n",
    "    \n",
    "    if len(filename_collection) != len(varnames):\n",
    "        raise ValueError(f'Year {year}, day {day_idx} has incomplete files')\n",
    "    \n",
    "    # Open with a lock to avoid race conditions when accessing files\n",
    "    ds = xr.open_mfdataset(filename_collection, combine='by_coords', parallel=True, lock=netcdf_lock)\n",
    "\n",
    "    # drop useless var\n",
    "    ds = ds.drop_vars('utc_date', errors='ignore')\n",
    "\n",
    "    # hourly --> 6 hourly\n",
    "    ds = ds.isel(time=slice(0, -1, 6))\n",
    "    \n",
    "    #  chunking\n",
    "    ds = ds.chunk(conf['RDA']['chunk_size_3d'])\n",
    "    ds_list.append(ds)\n",
    "    \n",
    "# concatenate\n",
    "ds_yearly = xr.concat(ds_list, dim='time')\n",
    "\n",
    "# save to zarr\n",
    "base_dir = conf['RDA']['save_loc'] + 'surf/' \n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "save_name = base_dir + conf['RDA']['prefix'] + '_surf_{}.zarr'.format(year)\n",
    "\n",
    "# ds_yearly.to_zarr(save_name, mode='w', consolidated=True, compute=True, encoding=dict_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36abe181-24fb-4e75-b0a3-f2717eb721e3",
   "metadata": {},
   "source": [
    "## Single-level accumulative variables\n",
    "\n",
    "**RDA**\n",
    "\n",
    "* Example file listing: `/glade/campaign/collections/rda/data/d633000/e5.oper.fc.sfc.accumu/197901`\n",
    "\n",
    "**ARCO**\n",
    "\n",
    "* Hourly data from `gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3`\n",
    "* Accumulate hourly to 6 hourly: `xarray.resample(time='6h').sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c90f4e20-8ae2-4f47-a9ff-9ed2b3ab6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1979\n",
    "N_days = 366 if year % 4 == 0 else 365\n",
    "\n",
    "config_name = os.path.realpath('data_config_6h.yml')\n",
    "\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7b66dcb-473d-4b75-85db-db2fd4749d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to zarr\n",
    "base_dir = conf['ARCO']['save_loc'] + 'accum/' \n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "compress = zarr.Blosc(cname='zstd', clevel=1, shuffle=zarr.Blosc.SHUFFLE, blocksize=0)\n",
    "\n",
    "\n",
    "chunk_size_3d = dict(chunks=(conf['ARCO']['chunk_size_3d']['time'],\n",
    "                             conf['ARCO']['chunk_size_3d']['latitude'],\n",
    "                             conf['ARCO']['chunk_size_3d']['longitude']))\n",
    "\n",
    "dict_encoding = {}\n",
    "\n",
    "for i_var, var in enumerate(conf['ARCO']['varname_accum']):\n",
    "    dict_encoding[var] = {'compressor': compress, **chunk_size_3d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73b9bcbe-09c8-40eb-9e24-810a6bec4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_1h = xr.open_zarr(\n",
    "    \"gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3\",\n",
    "    chunks=None,\n",
    "    storage_options=dict(token='anon'),)\n",
    "\n",
    "time_start = '{}-12-31T00'.format(year-1) # hourly accum var needs one extra day to accum on 6 hrs\n",
    "time_start_save = '{}-01-01T00'.format(year)\n",
    "time_end = '{}-12-31T23'.format(year)\n",
    "ERA5_1h_yearly = ERA5_1h.sel(time=slice(time_start, time_end))\n",
    "\n",
    "variables_levels = {}\n",
    "for varname in conf['ARCO']['varname_accum']:\n",
    "    variables_levels[varname] = None\n",
    "\n",
    "ERA5_1h_save = vu.ds_subset_everything(ERA5_1h_yearly, variables_levels)\n",
    "\n",
    "ERA5_1h_shifted = ERA5_1h_save.shift(time=-1)\n",
    "ERA5_6h = ERA5_1h_shifted.resample(time='6h').sum()\n",
    "ERA5_6h['time'] = ERA5_6h['time'] + pd.Timedelta(hours=6)\n",
    "\n",
    "ERA5_6h_save = ERA5_6h.sel(time=slice(time_start_save, time_end))\n",
    "\n",
    "ERA5_6h_save = ERA5_6h_save.chunk(conf['ARCO']['chunk_size_3d'])\n",
    "save_name = base_dir + conf['ARCO']['prefix'] + '_accum_{}.zarr'.format(year)\n",
    "# ERA5_6h_save.to_zarr(save_name, mode=\"w\", consolidated=True, compute=True, encoding=dict_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7049fd06-adad-42b0-ab6d-5348068f15e0",
   "metadata": {},
   "source": [
    "**Comparing accumulated hourly to the old directly available 6 hourly data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fed5eb54-ccf6-4629-aa61-2299193d370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA5_6h = xr.open_zarr(\n",
    "#     \"gs://gcp-public-data-arco-era5/ar/1959-2022-6h-1440x721.zarr\",\n",
    "#     chunks=None,\n",
    "#     storage_options=dict(token='anon'),)\n",
    "\n",
    "# tp_6h_ref = ERA5_6h['total_precipitation_6hr']\n",
    "# tp_6h_ref = tp_6h_ref.sel(time=slice(time_start_save, time_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50e7b14d-46fc-428d-871c-6cc59ee20730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.sum(np.array(ERA5_6h_save['total_precipitation'].isel(time=-1)) - np.array(tp_6h_ref.isel(time=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5144d188-0343-451e-b563-f0a61c6d0d74",
   "metadata": {},
   "source": [
    "### Static variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac18ded-bdf3-4464-9019-2e606d99f08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49eed24-b552-45b0-8a60-84b1c390c0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cd27bfa-886a-4c98-96be-6b450ead005d",
   "metadata": {},
   "source": [
    "## Others\n",
    "\n",
    "### Total precipitation from RDA\n",
    "\n",
    "\n",
    "```python\n",
    "xr_ARCO = xr.open_zarr('/glade/derecho/scratch/ksha/CREDIT_data/ERA5_plevel_base/test_data/surf_test.zarr')\n",
    "tp_ARCO = xr_ARCO['total_precipitation']\n",
    "\n",
    "base_dir = '/glade/campaign/collections/rda/data/d633000/e5.oper.fc.sfc.accumu/197901/'\n",
    "xr_RDA_CP = xr.open_dataset(base_dir+'e5.oper.fc.sfc.accumu.128_143_cp.ll025sc.1979010106_1979011606.nc')\n",
    "xr_RDA_LP = xr.open_dataset(base_dir+'e5.oper.fc.sfc.accumu.128_142_lsp.ll025sc.1979010106_1979011606.nc')\n",
    "\n",
    "xr_RDA_CP = xr_RDA_CP.drop_vars('utc_date', errors='ignore')\n",
    "xr_RDA_CP = xr_RDA_CP.rename({'CP': 'TP'})\n",
    "xr_RDA_LP = xr_RDA_LP.drop_vars('utc_date', errors='ignore')\n",
    "xr_RDA_LP = xr_RDA_LP.rename({'LSP': 'TP'})\n",
    "\n",
    "da = xr_RDA_CP + xr_RDA_LP\n",
    "\n",
    "time_deltas = pd.to_timedelta(da[\"forecast_hour\"].values, unit=\"h\")\n",
    "new_times = np.add.outer(da[\"forecast_initial_time\"].values, time_deltas)\n",
    "new_times = new_times.flatten()\n",
    "\n",
    "da_an = da.stack(time=(\"forecast_initial_time\", \"forecast_hour\"))\n",
    "da_an = da_an.drop_vars(['forecast_hour', 'forecast_initial_time', 'time'])\n",
    "da_an = da_an.assign_coords(time=new_times)\n",
    "\n",
    "for i_hour in range(10):\n",
    "    # i + 7 becuase ini_time = 06Z, fcst_lead_time starts from 01 hr\n",
    "    tp_ARCO_np = np.array(tp_ARCO.isel(time=i_hour+7))\n",
    "    da_np = np.array(da_an['TP'].isel(time=i_hour))\n",
    "    print(np.sum(np.abs(tp_ARCO_np - da_np)))\n",
    "\n",
    "# ARCO vs. RDA\n",
    "data_var = da['TP']\n",
    "tp_RDA = data_var.isel(forecast_initial_time=0)\n",
    "tp_RDA_np = np.array(tp_RDA)\n",
    "tp_ARCO_np = np.array(tp_ARCO.isel(time=slice(7, 7+12)))\n",
    "np.sum(np.abs(tp_ARCO_np[3, ...] - tp_RDA_np[3, ...]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652d8ac-031a-4508-a417-9eac0c5871f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa08066-4289-4781-902c-7e83e244857d",
   "metadata": {},
   "source": [
    "# Pre-process ERA5 pressure level data for CREDIT\n",
    "\n",
    "This notebook provides some keynotes on the preprocessing of ERA5 pressure level data\n",
    "\n",
    "* ARCO-ERA5 access\n",
    "* Mass-conserved vertical level subsetting\n",
    "* Stacking forecast lead time and initialization time for ERA forecast variables\n",
    "* Aggregating hourly quantities to 6 hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70332162-6c47-4172-a003-326059f10045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa740e32-0024-4dec-b2c9-ce7c7f92f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c060b962-c05f-42ea-b988-c0fca623f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.realpath('../libs/'))\n",
    "import verif_utils as vu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068fbd7-18c4-496a-a1f7-c63f26c59544",
   "metadata": {},
   "source": [
    "## Get data from Google Cloud ARCO-ERA5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b81af18-faac-450b-9979-683e4ffb1dec",
   "metadata": {},
   "source": [
    "* Source: https://console.cloud.google.com/storage/browser/gcp-public-data-arco-era5\n",
    "* GitHub: https://github.com/google-research/arco-era5\n",
    "* Latest hourly: gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afe36c4d-711a-4fe3-bbf6-02bee5f64ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data begins at 1900 with NaNs\n",
    "# subset to 1940-01-01 or later to get actual values\n",
    "ERA5_1h = xr.open_zarr(\n",
    "    \"gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3\",\n",
    "    chunks=None,\n",
    "    storage_options=dict(token='anon'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc929e6-4709-4d69-832f-a32d3926c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = '1979-01-01T00'\n",
    "time_end = '1979-12-31T23'\n",
    "ERA5_1h_yearly = ERA5_1h.sel(time=slice(time_start, time_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889988be-5eb8-4224-b98a-2c4222f9091e",
   "metadata": {},
   "source": [
    "## Vertical coordinate subsetting with conserved total column properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f569cd-4287-4803-9836-4ed2dfc00992",
   "metadata": {},
   "source": [
    "#### 1D example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf8adc0-1cd7-4f64-94cd-4e661b5e4c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integral_conserved_subset_1d(x_column, level_p, ind_select):\n",
    "    # allocate the output array\n",
    "    out_column_a = np.empty(len(ind_select)-1); out_column_a.fill(np.nan)\n",
    "\n",
    "    # compute the level difference\n",
    "    diff_level_p = np.diff(level_p)\n",
    "    \n",
    "    # compute the area of each level using trapz rule\n",
    "    x_column_midpoint = 0.5 * (x_column[1:] + x_column[:-1])\n",
    "    x_column_area = x_column_midpoint * diff_level_p\n",
    "\n",
    "    # subsetting levels through a way that conserves the total integral\n",
    "    for i_ind, ind in enumerate(ind_select[:-1]):\n",
    "        ind_start = ind\n",
    "        ind_end = ind_select[i_ind+1]\n",
    "        out_column_a[i_ind] = np.sum(x_column_area[ind_start:ind_end]) / (level_p[ind_end] - level_p[ind_start])\n",
    "\n",
    "    return out_column_a\n",
    "\n",
    "def integral_conserved_subset_4d(x_grid, level_p, ind_select):\n",
    "    '''\n",
    "    Given selected indices, subset a 4D grid (time, level, latitude, longitude)\n",
    "    while conserving the total vertical integral.\n",
    "\n",
    "    Args:\n",
    "        x_grid: 4D grid of data with shape (time, level, latitude, longitude)\n",
    "        level_p: 1D array of pressure levels\n",
    "        ind_select: np.array of int values that select specific levels\n",
    "    Returns:\n",
    "        out_grid: subsetted copy of x_grid with conserved integral\n",
    "    '''\n",
    "    # Prepare the output array with the same dimensions except for the level dimension\n",
    "    out_grid = np.empty((x_grid.shape[0], len(ind_select)-1, x_grid.shape[2], x_grid.shape[3]))\n",
    "    out_grid.fill(np.nan)\n",
    "\n",
    "    # Compute the level differences\n",
    "    diff_level_p = np.diff(level_p)\n",
    "    \n",
    "    # Compute the midpoints along the level dimension\n",
    "    x_grid_midpoint = 0.5 * (x_grid[:, 1:, :, :] + x_grid[:, :-1, :, :])\n",
    "    \n",
    "    # Compute the area of each level using the trapezoidal rule\n",
    "    x_grid_area = x_grid_midpoint * diff_level_p[:, np.newaxis, np.newaxis]\n",
    "\n",
    "    # Subsetting levels in a way that conserves the total integral\n",
    "    for i_ind, ind in enumerate(ind_select[:-1]):\n",
    "        ind_start = ind\n",
    "        ind_end = ind_select[i_ind + 1]\n",
    "        \n",
    "        # Sum areas over the selected levels and normalize by the level difference\n",
    "        out_grid[:, i_ind, :, :] = np.sum(x_grid_area[:, ind_start:ind_end, :, :], axis=1) / (level_p[ind_end] - level_p[ind_start])\n",
    "\n",
    "    return out_grid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb88f6ba-d01e-4af6-935b-676bd8a56a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_1h = xr.open_zarr(\n",
    "    \"gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3\",\n",
    "    chunks=None,\n",
    "    storage_options=dict(token='anon'),)\n",
    "\n",
    "time_start = '1979-01-01T00'\n",
    "time_end = '1979-12-31T23'\n",
    "ERA5_1h = ERA5_1h.sel(time=slice(time_start, time_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef950ad1-e81e-4e4d-9db7-7861fc778f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the full pressure level coordinates\n",
    "level_p = np.array(ERA5_1h['level'])\n",
    "ind_select = np.array([0, 1, 2, 3, 5, 17, 24, 25, 26, 32, 36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2400577b-91a5-49ea-8853-cf7ff3983e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_p_select = level_p[ind_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d2b03fe-50c4-47a5-8fa6-ec6d5187bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a piece of example data\n",
    "ds_full_level = ERA5_1h['temperature'].isel(time=slice(0, 2))\n",
    "test_data = np.array(ds_full_level)\n",
    "x_column = test_data[1, :, 100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef12732c-c4ee-422b-87f6-c8a7c49abbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([279.89435, 269.9138 , 260.95508, 238.76361, 226.11641, 213.80423,\n",
       "       206.43935, 201.34184, 203.07797, 205.13799, 208.43266, 211.47073,\n",
       "       212.7036 , 214.33925, 215.40028, 215.38864, 214.9771 , 213.86823,\n",
       "       216.5767 , 220.52747, 224.7109 , 227.27908, 229.39972, 233.72934,\n",
       "       238.36395, 242.1929 , 245.68329, 247.31508, 248.88345, 250.06119,\n",
       "       250.15376, 248.66463, 245.14752, 242.35803, 242.7212 , 243.93507,\n",
       "       245.16734], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34e085d6-39b6-4d6b-9640-14b53ed6d8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertical integral of the original data: 228125.6005706787\n"
     ]
    }
   ],
   "source": [
    "# compute the vertical intergral that we need to conserve\n",
    "int_original = np.trapz(x_column, level_p)\n",
    "print('vertical integral of the original data: {}'.format(int_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b64fdb4-a7bb-4b6d-988e-ec5933c35d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_column_a = integral_conserved_subset_1d(x_column, level_p, ind_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71d09148-e46e-4e5e-9def-7a4049ecf903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([274.90405273, 265.43444824, 249.85934448, 224.95219727,\n",
       "       211.09089213, 225.47704642, 240.27842712, 243.93809509,\n",
       "       248.41558584, 243.54293442])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_column_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ad63d31-4a22-40e2-8cb8-4f7b49c400ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertical integral after subsetting using conserved area: 228125.6005706787\n"
     ]
    }
   ],
   "source": [
    "level_p_select = level_p[ind_select]\n",
    "int_x = np.sum(out_column_a * np.diff(level_p_select))\n",
    "print('vertical integral after subsetting using conserved area: {}'.format(int_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdfdab34-0b18-4ca2-9481-da01ed14dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertical integral after subsetting using a simple indexing: 228863.49476623535\n"
     ]
    }
   ],
   "source": [
    "# bad example: what if we indexing\n",
    "x_column_select = x_column[ind_select]\n",
    "int_x_bad = np.trapz(x_column_select, level_p_select)\n",
    "print('vertical integral after subsetting using a simple indexing: {}'.format(int_x_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eed2d9f4-6fd1-4a09-b849-a6d1aa1f6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_subset(out_column_a, level_p, ind_select):\n",
    "    '''\n",
    "    Estimate the original x_column from out_column_a using 1D interpolation.\n",
    "\n",
    "    Args:\n",
    "        out_column_a: The subsetted array produced by integral_conserved_subset_1d\n",
    "        level_p: The pressure levels array\n",
    "        ind_select: Indices used for subsetting x_column\n",
    "        \n",
    "    Returns:\n",
    "        x_column_est: Interpolated x_column\n",
    "    '''\n",
    "    # Define the pressure levels at the selected indices\n",
    "    level_p_selected = level_p[ind_select]\n",
    "    level_p_midpoint = 0.5 * (level_p_selected[1:] + level_p_selected[:-1])\n",
    "    \n",
    "    x_column_est = np.interp(level_p, level_p_midpoint, out_column_a)\n",
    "    \n",
    "    return x_column_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5f8e5a8-5ed2-4936-aba9-8355ae42229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column_ = reverse_subset(out_column_a, level_p, ind_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d2958f1-c130-4145-85bc-e4d818346f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([274.90405273, 270.16925049, 260.24274699, 242.74301671,\n",
       "       224.71725989, 217.6096183 , 238.42825454, 242.10826111,\n",
       "       245.05746778, 245.49199498, 243.54293442])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_column_[ind_select] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4598142b-1196-4cac-97de-92d6ac5f8e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([279.89435, 269.9138 , 260.95508, 238.76361, 213.80423, 213.86823,\n",
       "       238.36395, 242.1929 , 245.68329, 245.14752, 245.16734],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_column[ind_select]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54436700-68bf-4d47-beec-d4be671d8a8c",
   "metadata": {},
   "source": [
    "#### 4D example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbab2012-57a2-4e2d-a7c1-68f03b2427fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a piece of example data\n",
    "ds_full_level = ERA5_1h['temperature'].isel(time=slice(0, 2))\n",
    "test_data = np.array(ds_full_level)\n",
    "x_grid = test_data[1:5, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9051a678-7d06-472a-83fd-afbb07f71d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertical integral of the original data: 256855241191.82944\n"
     ]
    }
   ],
   "source": [
    "grid_shape = x_grid.shape\n",
    "int_original = 0\n",
    "\n",
    "for i_time in range(grid_shape[0]):\n",
    "    for i_x in range(grid_shape[2]):\n",
    "        for i_y in range(grid_shape[3]):\n",
    "            int_original += np.trapz(x_grid[i_time, :, i_x, i_y], level_p)\n",
    "            \n",
    "print('vertical integral of the original data: {}'.format(int_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c87045b-fbd3-4f18-b8fb-d427061b49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_grid_a = integral_conserved_subset_4d(x_grid, level_p, ind_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c826cca6-8697-4555-80e1-1f748d2f6a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertical integral of the subsetted data: 256855241191.82962\n"
     ]
    }
   ],
   "source": [
    "int_x = 0\n",
    "level_p_diff = np.diff(level_p_select)\n",
    "\n",
    "for i_time in range(grid_shape[0]):\n",
    "    for i_x in range(grid_shape[2]):\n",
    "        for i_y in range(grid_shape[3]):\n",
    "            int_x += np.sum(out_grid_a[i_time, :, i_x, i_y] * level_p_diff)\n",
    "            \n",
    "print('vertical integral of the subsetted data: {}'.format(int_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd2313f-b284-49c5-8235-12e3629419ae",
   "metadata": {},
   "source": [
    "## How to combine fcst lead time and init time dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b865a21-51ad-42f4-83aa-01350e7edbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f9ccc9-10c7-4384-9f3b-39bc75dd3d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1861711\n",
      "0.18500406\n",
      "0.18471201\n",
      "0.18455735\n",
      "0.1844524\n",
      "0.18450773\n",
      "0.25197998\n",
      "0.2279189\n",
      "0.27061352\n",
      "0.26860496\n"
     ]
    }
   ],
   "source": [
    "# my collection: time_start = '1979-01-01T00'; time_end = '1979-01-01T23'\n",
    "xr_ARCO = xr.open_zarr('/glade/derecho/scratch/ksha/CREDIT_data/ERA5_plevel_base/test_data/surf_test.zarr')\n",
    "tp_ARCO = xr_ARCO['total_precipitation']\n",
    "\n",
    "base_dir = '/glade/campaign/collections/rda/data/d633000/e5.oper.fc.sfc.accumu/197901/'\n",
    "xr_RDA_CP = xr.open_dataset(base_dir+'e5.oper.fc.sfc.accumu.128_143_cp.ll025sc.1979010106_1979011606.nc')\n",
    "xr_RDA_LP = xr.open_dataset(base_dir+'e5.oper.fc.sfc.accumu.128_142_lsp.ll025sc.1979010106_1979011606.nc')\n",
    "\n",
    "xr_RDA_CP = xr_RDA_CP.drop_vars('utc_date', errors='ignore')\n",
    "xr_RDA_CP = xr_RDA_CP.rename({'CP': 'TP'})\n",
    "xr_RDA_LP = xr_RDA_LP.drop_vars('utc_date', errors='ignore')\n",
    "xr_RDA_LP = xr_RDA_LP.rename({'LSP': 'TP'})\n",
    "\n",
    "da = xr_RDA_CP + xr_RDA_LP\n",
    "\n",
    "time_deltas = pd.to_timedelta(da[\"forecast_hour\"].values, unit=\"h\")\n",
    "new_times = np.add.outer(da[\"forecast_initial_time\"].values, time_deltas)\n",
    "new_times = new_times.flatten()\n",
    "\n",
    "da_an = da.stack(time=(\"forecast_initial_time\", \"forecast_hour\"))\n",
    "da_an = da_an.drop_vars(['forecast_hour', 'forecast_initial_time', 'time'])\n",
    "da_an = da_an.assign_coords(time=new_times)\n",
    "\n",
    "for i_hour in range(10):\n",
    "    # i + 7 becuase ini_time = 06Z, fcst_lead_time starts from 01 hr\n",
    "    tp_ARCO_np = np.array(tp_ARCO.isel(time=i_hour+7))\n",
    "    da_np = np.array(da_an['TP'].isel(time=i_hour))\n",
    "    print(np.sum(np.abs(tp_ARCO_np - da_np)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7219ff3-7006-41b8-83c6-700ac02cfd58",
   "metadata": {},
   "source": [
    "## How to accumulate hourly to 6 hourly\n",
    "\n",
    "* The time coordinate is \"ending-time\". \n",
    "* For accumulating hourly quantities to 6-hourly, add index-0, 1, 2, 3, 4, 5 hourly values will give the accumulated result on index-0 for 6 hourly.\n",
    "* Example: hourly quantities on 1959-01-02T01Z, 02Z, 03Z, 04Z, 05Z, 06Z accumulates to 1959-01-02T06Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42cda1c1-1989-4fb0-9e04-12b37d810ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_1h = xr.open_zarr(\n",
    "    \"gs://gcp-public-data-arco-era5/ar/1959-2022-full_37-1h-0p25deg-chunk-1.zarr-v2/\",\n",
    "    chunks=None,\n",
    "    storage_options=dict(token='anon'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2ca480a-cc7b-416d-a060-4b3cf3774b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_1h = ERA5_1h['total_precipitation']\n",
    "tp_1h = tp_1h.isel(time=slice(0, 96))\n",
    "tp_1h_np = np.array(tp_1h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c014649d-4e94-4878-9dce-bd634767fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'time' (time: 6)> Size: 48B\n",
      "array(['1959-01-02T01:00:00.000000000', '1959-01-02T02:00:00.000000000',\n",
      "       '1959-01-02T03:00:00.000000000', '1959-01-02T04:00:00.000000000',\n",
      "       '1959-01-02T05:00:00.000000000', '1959-01-02T06:00:00.000000000'],\n",
      "      dtype='datetime64[ns]')\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 48B 1959-01-02T01:00:00 ... 1959-01-02T06:...\n"
     ]
    }
   ],
   "source": [
    "tp_6h_accum = np.sum(tp_1h_np[25:31, ...], axis=0)\n",
    "print(tp_1h['time'][25:31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5bf057a-857d-4df9-82e0-0986d659d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_6h = xr.open_zarr(\n",
    "    \"gs://gcp-public-data-arco-era5/ar/1959-2022-6h-1440x721.zarr\",\n",
    "    chunks=None,\n",
    "    storage_options=dict(token='anon'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d03ac80-426f-4105-a0d0-b8e24a60529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_6h = ERA5_6h['total_precipitation_6hr']\n",
    "tp_6h = tp_6h.isel(time=slice(0, 16))\n",
    "tp_6h_np = np.array(tp_6h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2aa6de75-5e96-4786-8a86-b3727562c0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "<xarray.DataArray 'time' ()> Size: 8B\n",
      "array('1959-01-02T06:00:00.000000000', dtype='datetime64[ns]')\n",
      "Coordinates:\n",
      "    time     datetime64[ns] 8B 1959-01-02T06:00:00\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(tp_6h_np[5, ...] - tp_6h_accum))\n",
    "print(tp_6h['time'][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d2b04-234c-4d54-ac6a-23e750bc12ab",
   "metadata": {},
   "source": [
    "0.0 means accumulated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7ef1f78c-429a-4225-ab54-df9c39fc8d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'total_precipitation' ()> Size: 4B\n",
      "array(0., dtype=float32)\n",
      "Coordinates:\n",
      "    time     datetime64[ns] 8B 1959-01-02T06:00:00\n"
     ]
    }
   ],
   "source": [
    "ERA5_1h_sub = ERA5_1h.isel(time=slice(0, 96))\n",
    "ERA5_tp = ERA5_1h_sub['total_precipitation']\n",
    "data_shifted = ERA5_tp.shift(time=-1)\n",
    "data_6hourly = data_shifted.resample(time='6h').sum()\n",
    "data_6hourly['time'] = data_6hourly['time'] + pd.Timedelta(hours=6)\n",
    "\n",
    "print(np.sum(np.abs(tp_6h_np[5, ...] - data_6hourly[4, ...])))\n",
    "\n",
    "# # the basic for loop numpy version\n",
    "# ERA5_tp_np = np.array(ERA5_tp)\n",
    "\n",
    "# ERA5_tp_np_6h = np.empty((15, 721, 1440))\n",
    "\n",
    "# for i_6h, i_1h in enumerate(np.arange(0, 96, 6)[:-1]):\n",
    "#     ERA5_tp_np_6h[i_6h, ...] = np.sum(ERA5_tp_np[i_1h+1:i_1h+7, ...], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbf7550-ca81-4986-b6b8-9e9e6dd5483c",
   "metadata": {},
   "source": [
    "`resample(time='6h').sum()` works but the time coord is shifted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd84ad7-5f65-4745-8482-70cb0f33e748",
   "metadata": {},
   "source": [
    "## Preprocess examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcee8fac-9ceb-488c-b598-fb0c015dab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "sys.path.insert(0, os.path.realpath('../libs/'))\n",
    "import verif_utils as vu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa36489-f337-49bb-9179-981b7e814d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x1551b044cbc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a preprocess example\n",
    "\n",
    "# Data begins at 1900 will NaNs\n",
    "# subset to 1940-01-01 or later to get actual values\n",
    "ERA5_1h = xr.open_zarr(\n",
    "    \"gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3\",\n",
    "    chunks=None,\n",
    "    storage_options=dict(token='anon'),)\n",
    "\n",
    "time_start = '1979-01-01T00'\n",
    "time_end = '1979-01-01T23'\n",
    "\n",
    "ERA5_1h_yearly = ERA5_1h.sel(time=slice(time_start, time_end))\n",
    "\n",
    "\n",
    "variables_levels = {}\n",
    "variables_levels['geopotential'] = None\n",
    "variables_levels['u_component_of_wind'] = None\n",
    "variables_levels['v_component_of_wind'] = None\n",
    "variables_levels['temperature'] = None\n",
    "variables_levels['specific_humidity'] = None\n",
    "variables_levels['specific_cloud_ice_water_content'] = None\n",
    "variables_levels['specific_cloud_liquid_water_content'] = None\n",
    "\n",
    "ERA5_1h_var = vu.ds_subset_everything(ERA5_1h_yearly, variables_levels)\n",
    "ERA5_1h_var.to_zarr('/glade/derecho/scratch/ksha/CREDIT_data/ERA5_plevel_base/test_data/upper_air_test.zarr')\n",
    "\n",
    "variables_levels = {}\n",
    "variables_levels['total_precipitation'] = None\n",
    "variables_levels['total_column_water'] = None\n",
    "variables_levels['total_column_water_vapour'] = None\n",
    "variables_levels['evaporation'] = None\n",
    "variables_levels['surface_pressure'] = None\n",
    "variables_levels['geopotential_at_surface'] = None\n",
    "variables_levels['top_net_solar_radiation'] = None\n",
    "variables_levels['top_net_thermal_radiation'] = None\n",
    "variables_levels['surface_net_solar_radiation'] = None\n",
    "variables_levels['surface_net_thermal_radiation'] = None\n",
    "variables_levels['surface_latent_heat_flux'] = None\n",
    "variables_levels['surface_sensible_heat_flux'] = None\n",
    "\n",
    "ERA5_1h_var_surf = vu.ds_subset_everything(ERA5_1h_yearly, variables_levels)\n",
    "ERA5_1h_var_surf.to_zarr('/glade/derecho/scratch/ksha/CREDIT_data/ERA5_plevel_base/test_data/surf_test.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ba908-c295-4c28-a95c-a166c7290b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b14a1-0442-417b-a970-02cbe7e2c4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
